<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>Speech Synthesis Programming Guide: Designing and Implementing an Application That Speaks</title>
	<meta id="Generator" name="Generator" content="Gutenberg"/>
	<meta id="GeneratorVersion" name="GeneratorVersion" content="v132"/>
	<meta http-equiv="content-type" content="text/html;charset=utf-8"/>
	<meta id="Copyright" name="Copyright" content="Copyright 2009 Apple Inc. All Rights Reserved."/>
	<meta id="IndexTitle" name="IndexTitle" content="Designing and Implementing an Application That Speaks"/>
	<meta id="xcode-display" name="xcode-display" content="render"/>
	<meta id="toc-file" name="toc-file" content="../toc.html"/>
	<meta id="RESOURCES" content="../../../../Resources" />
	
	<link rel="stylesheet" type="text/css" href="../../../../Resources/CSS/frameset_styles.css"/>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/prototype.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/scriptaculous.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/page.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/pedia.js"></script>
	<!--[if lte IE 6]>
		<style type="text/css">
			/*<![CDATA[*/ 
			html {overflow-x:auto; overflow-y:hidden;  }
			/*]]>*/
		</style>
	<![endif]-->
</head>    
<body bgcolor="#ffffff" onload="initialize_page();"><a name="//apple_ref/doc/uid/TP40004365-CH4" title="Designing and Implementing an Application That Speaks"></a>
    <noscript>
    <div id="tocMenu">
        <iframe id="toc_content" name="toc_content" SRC="../toc.html" width="210" height="100%" align="left" frameborder="0">This document set is best viewed in a browser that supports iFrames.</iframe>
    </div>
    </noscript>
    <div id="bodyText">
        <a name="top"></a>
        <div class="hideOnPrint hideInXcode">
        <!-- start of header -->
        <!--#include virtual="/includes/framesetheader" -->
        <!-- end of header -->
        </div>
        
        <!-- start of path -->
<div class="breadcrumb hideOnPrint hideInXcode"><a href="http://developer.apple.com/" target="_top">ADC Home</a> &gt; <a href="../../../../../referencelibrary/index.html#//apple_ref/doc/uid/TP30000943" target="_top">Reference Library</a> &gt; <a href="../../../../index.html#//apple_ref/doc/uid/TP30000440" target="_top">Guides</a> &gt; <a href="../../../index.html#//apple_ref/doc/uid/TP30000440-TP30000437" target="_top">User Experience</a> &gt; <a href="../../../SpeechTechnologies-date.html#//apple_ref/doc/uid/TP30000440-TP30000437-TP30000576" target="_top">Speech Technologies</a> &gt; <a href="../Introduction/Introduction.html#//apple_ref/doc/uid/TP40004365-CH1-DontLinkElementID_41">Speech Synthesis Programming Guide</a> &gt; </div><br class="hideInXcode"/><!-- end of path -->
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../SpeechOverview/SpeechOverview.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../FineTuning/FineTuning.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCUpperSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" hideText="Hide TOC" showText="Show TOC" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <hr />
        
        
        <a name="//apple_ref/doc/uid/TP40004365-CH4-SW2" title="Designing and Implementing an Application That Speaks"></a><h1>Designing and Implementing an Application That Speaks</h1><p>This chapter gathers together some strategies to consider and guidelines to follow as you design (or retrofit) an application to produce spoken output. It begins with a survey of different implementation strategies you should consider to find the one that meets your goals. It then provides user-interface guidelines you should keep in mind as you design your application. Finally, this chapter outlines the speech synthesis APIs available to you and provides some examples that show how to get started.</p>
<!-- This template is being used for both PDF and HTML. -->

    
    <h4>In this section:</h4>
    
    
    <p class="blockquote">
    
        
			
			
				<a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_16">Strategies for Incorporating Synthesized Speech</a>
				
			<br/>
			
        
			
			
				<a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-SW3">User Interface Design Guidelines for Speech</a>
				
			<br/>
			
        
			
			
				<a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-SW1">Carbon and Cocoa Speech Synthesis APIs Compared</a>
				
			<br/>
			
        
			
			
				<a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-SW8">Implementing Basic Speech Synthesis Tasks Using Cocoa and Carbon</a>
				
			<br/>
			
        
			
			
				<a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_22">Using AppleScript to Produce Spoken Output</a>
				
			<br/>
			
        

    </p><br/>

<a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_16" title="Strategies for Incorporating Synthesized Speech"></a><h2>Strategies for Incorporating Synthesized Speech</h2><p>Spoken output is a natural enhancement for a broad range of applications, from games to productivity applications to educational applications. For example, if you’re designing an application for language-learning, it’s clear you need to provide accurately pronounced speech users can emulate. If you’re developing a game, you probably want to provide a large set of expressive phrases your characters can speak. But synthesized speech can also enhance an application that doesn’t have such obvious reasons to produce spoken output, because it can provide users with a more convenient and more enjoyable way to interact with the application.</p><p>As you design your application, look for ways synthesized speech can enhance the user interface. A few suggestions are included in <span class="content_text"><a href="UsingSpeech.html#//apple_ref/doc/uid/TP40004365-CH4-SW3">“User Interface Design Guidelines for Speech.”</a></span> The following sections describe ways you can use synthesized speech in your application, divided into three categories that roughly correspond to the levels of effort required to implement them.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_17" title="Take Advantage of System-Provided Functionality"></a><h3>Take Advantage of System-Provided Functionality</h3><p>Even if you do not include any speech-specific code in your application, users will be able to hear most of the text displayed in your application spoken aloud by a system voice. In the Text to Speech pane of Speech preferences, users can create a key combination to use when they want to hear the text they’ve selected in any application. In the same preference pane, users can also choose to hear the text of alerts spoken aloud (this is a feature known as Talking Alerts) and to be told when an application requires attention.</p><p>You do not have to do anything special to allow your users to benefit from these features; to the contrary, if you use standard, system-supplied APIs and technologies, it comes for free. Selectable text that appears in your application, including user-supplied text, can be spoken aloud when users press their designated key combination or when they select Speech > Start Speaking Text from the Services menu item. (Note that the Services menu item is included by default in Cocoa and Carbon applications; for more information, see <em><a href="../../../../Cocoa/Conceptual/SysServices/index.html#//apple_ref/doc/uid/10000101i" target="_top">System Services</a></em> and <em><a href="../../../../Carbon/Conceptual/appservices/index.html#//apple_ref/doc/uid/TP30000993" target="_top">Setting Up Your Carbon Application to Use the Services Menu</a></em>.) When your application uses system-provided mechanisms for displaying alerts, the Talking Alerts feature automatically speaks the alert text.</p><p>You may find that these built-in features meet your application’s speech needs. If, however, you want to enhance and customize the spoken output in your application to differentiate it from competing products, read the following sections to explore ways you can do this.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_18" title="Provide Some Customization "></a><h3>Provide Some Customization </h3><p>In addition to allowing users to select text to hear spoken aloud, your application can speak when it encounters specific conditions or performs specific tasks. For example, your application could guide new users by describing the steps required to accomplish common tasks. The speech synthesis APIs provide functions and methods you can use to associate spoken output with application-specific tasks and events (for more information on how to do this, see <span class="content_text"><a href="../FineTuning/FineTuning.html#//apple_ref/doc/uid/TP40004365-CH5-SW9">“Synchronize Speech With Application-Specific Actions”</a></span>).</p><p>If you want to have more control over the production of speech in your application, you can override some of the default behaviors of the synthesizer. One way to do this is to use Carbon speech synthesis functions to change speech-channel attributes, such as speech rate and pitch. Another way to do this is to use embedded speech commands (described in <span class="content_text"><a href="../SpeechOverview/SpeechOverview.html#//apple_ref/doc/uid/TP40004365-CH3-SW5">“Control Speech Quality Using Embedded Speech Commands”</a></span>) and insert them as needed in the text to be spoken. The synthesizer uses these commands to alter the intonation of words and phrases by controlling the pitch, word emphasis, and pause length, among other attributes. This technique is especially useful if you want ensure the correct pronunciation of a proper noun (such as your company name) or if the spoken content must conform to specific requirements (such as in a language-learning application or other educational software). Embedded speech commands are available regardless of the programming language you’re using.</p><div class="notebox"><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_45" title="Note"></a><p><strong>Note:</strong>&nbsp;Even though user-supplied text does not contain embedded commands, you can add them when it makes sense. For example, you might place extra emphasis on words or phrases users surround with asterisks or underscores.</p></div><p></p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_19" title="Provide Advanced Customization"></a><h3>Provide Advanced Customization</h3><p>The phonemic and TUNE input-processing modes allow you to make fine-grained adjustments to spoken output. For example, you can stipulate the pronunciation of a word by giving the synthesizer the individual phonemes that comprise the word. </p><p>Using the TUNE input-processing mode, you can reproduce all the minute variations in pitch and rate of an actual utterance, allowing your application to produce speech that replicates some of the subtleties of human speech. If you want your application to produce speech that follows such exact specifications, see <span class="content_text"><a href="../FineTuning/FineTuning.html#//apple_ref/doc/uid/TP40004365-CH5-SW4">“Use Phoneme Modifiers to Adjust Pronunciation”</a></span> and <span class="content_text"><a href="../FineTuning/FineTuning.html#//apple_ref/doc/uid/TP40004365-CH5-SW7">“Use the TUNE Format to Supply Complex Pitch Contours.”</a></span></p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW3" title="User Interface Design Guidelines for Speech"></a><h2>User Interface Design Guidelines for Speech</h2><p>As described in <span class="content_text"><a href="../SpeechOverview/SpeechOverview.html#//apple_ref/doc/uid/TP40004365-CH3-SW10">“Why Use Synthesized Speech?,”</a></span> there are many ways to enhance your application by providing spoken output. For example, you can use speech to notify users of something that happened in the background, such as “Your download is finished” or “You have a meeting in 15 minutes.“ Essentially, spoken output is another facet of the user interface and, as such, it should follow most of the high-level guidelines in <em><a href="../../AppleHIGuidelines/index.html#//apple_ref/doc/uid/20000957" target="_top">Apple Human Interface Guidelines</a></em>. In addition to those guidelines, keep in mind this section’s design considerations and speech-specific guidelines as you design your application. </p><p>Consider providing spoken confirmation of information users enter or selections they make. For example, a user may not be looking at the screen when typing in data from another source, and spoken confirmation of the input would be welcome. Similarly, if a user inadvertently selects the wrong item from a long list, spoken confirmation of each choice would immediately alert the user to any mistakes. </p><p>When using speech to notify users that an event has occurred, consider pausing for a few seconds between the visual display of the event (such as a dialog) and the spoken message. Speech is an effective way to get users’s attention if they are not already looking at the screen, but if they are, the spoken notification might seem redundant. Inserting a delay between the visual and aural notification gives users the opportunity to respond to the event without hearing any speech. If such a pause makes sense in your application, be sure to provide a way for users to customize its length.</p><p>To provide a consistent and enjoyable speech experience to your users, follow these guidelines: </p><ul class="ul"><li class="li"><p>Provide a way for users to turn on and off the spoken output your application produces. Hearing-impaired users will not benefit from the speech your application generates, and other users may not like it or may use your application in situations that require silence (such as in a library). Consider your target market carefully before you decide to make speech the default setting. </p></li><li class="li"><p>Be sure to provide a visual alternative to all spoken (or aural) communication your application produces. Users should be able to choose between spoken and visual communication without losing access to any information or functionality.</p></li><li class="li"><p>As much as possible, provide ways for users to customize the speech they hear. For example, users should be able to choose a pleasing voice and to set the speech rate and pitch to comfortable levels.</p></li><li class="li"><p>When testing your application, be sure to listen to all spoken output your application generates. This way, you’ll be able to catch incorrect and ambiguous pronunciations and fix them with embedded speech commands and phoneme modifiers.</p></li><li class="li"><p>As with written alerts, spoken alerts should tell the user what happened, why it happened, and what the user can do about it. For more guidelines on writing effective alert messages, see <em><a href="../../AppleHIGuidelines/index.html#//apple_ref/doc/uid/20000957" target="_top">Apple Human Interface Guidelines</a></em>.</p></li><li class="li"><p>As much as possible, express complicated ideas in a few short sentences instead of one long sentence. It’s much harder for users to process complicated spoken information because they can’t go back and reread the parts they missed or didn’t understand. Effective use of punctuation can also help make complex sentences easier to understand. This is because the synthesizer, like a human speaker, pauses when it encounters commas, semicolons, and periods. For more information on how to draw users’s attention to the important information within a sentence, see <span class="content_text"><a href="../FineTuning/FineTuning.html#//apple_ref/doc/uid/TP40004365-CH5-SW2">“Four Ways to Improve Spoken Output.”</a></span></p></li><li class="li"><p>Be sure to document the speech capabilities of your application. If users don’t know what features are available and how they can customize them, they might not ever use them.</p></li></ul><a name="//apple_ref/doc/uid/TP40004365-CH4-SW1" title="Carbon and Cocoa Speech Synthesis APIs Compared"></a><h2>Carbon and Cocoa Speech Synthesis APIs Compared</h2><div class="importantbox"><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_46" title="Important:"></a><p><strong>Important:</strong>&nbsp;As long as your application can access the Application Services framework, it can use the Carbon speech synthesis API, regardless of the programming language you’re developing in. This means that you can create a Cocoa application, or even a command-line tool, include the <code>ApplicationServices.framework</code>, and call Carbon speech synthesis functions to implement speech-generation tasks.</p><p></p></div><p>Before you begin designing your application with synthesized speech in mind, note that the type of customization you plan to do has some impact on your choice of API. Both Carbon and Cocoa supply basic speech-synthesis functionality, but the Carbon API provides more programmatic control over speech attributes. Unlike the Carbon speech synthesis API, the <code>NSSpeechSynthesizer</code> class defined in the Application Kit does not support the ability to convert text to phonemes or to change speech attributes. If you don’t plan to take advantage of the programmatic features now or in a future version of your application, you can use the Cocoa API without worrying about having to redesign and recode the application later. If, however, you want to support advanced capabilities (or there’s a chance that you might do so in the future), you should consider using the Carbon API from the beginning. </p><p>Although you can mix the Cocoa and Carbon speech synthesis APIs in a single application, you may experience a few difficulties because of differences in implementation. For example, if you specify a voice that the current speech synthesizer doesn’t support, in Carbon you must explicitly close the current speech channel and open a new one to use the new voice, whereas in Cocoa this process is automatic. You may find that your best option is to develop the application in Cocoa, but use the Carbon speech synthesis API for all speech-related tasks.</p><p>Before you choose an API, bear in mind that you can accomplish a great deal of speech customization by adding embedded commands to the text your application passes to the synthesizer. However, a potential disadvantage to using embedded commands is that you must add the appropriate embedded commands to every occurrence of a particular word to specify its pronunciation. Contrast this with calling a function that sets a speech attribute for all spoken output that passes through a speech channel. Depending on your circumstances, however, you may decide that this disadvantage is outweighed by the finer-grained control that comes with using embedded commands.</p><p>The remainder of this section provides brief overviews of the Cocoa and Carbon speech synthesis APIs. For in-depth reference information on these APIs, see  <em><a href="../../../../Cocoa/Reference/ApplicationKit/Classes/NSSpeechSynthesizer_Class/index.html#//apple_ref/doc/uid/TP40004114" target="_top">NSSpeechSynthesizer Class Reference</a></em> and <em><a href="../../../../Carbon/Reference/Speech_Synthesis_Manager/index.html#//apple_ref/doc/uid/TP30000211" target="_top">Speech Synthesis Manager Reference</a></em>.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_20" title="Overview of the Cocoa Speech Synthesis API"></a><h3>Overview of the Cocoa Speech Synthesis API</h3><p>The Cocoa API includes the <code><a href="../../../../Cocoa/Reference/ApplicationKit/Classes/NSSpeechSynthesizer_Class/Reference/Reference.html#//apple_ref/occ/cl/NSSpeechSynthesizer" target="_top">NSSpeechSynthesizer</a></code> class, which handles a number of speech synthesis tasks in a way native to Objective-C. When you create and initialize an instance of <code>NSSpeechSynthesizer</code>, a speech channel is created and a voice (either the default system voice or one you designate in the initialization method) is associated with the object. The <code>NSSpeechSynthesizer</code> object is your application’s conduit to the Speech Synthesis framework.</p><p>The <code>NSSpeechSynthesizer</code> class defines methods that allow you to:</p><ul class="spaceabove"><li class="li"><p>Get information about a voice (such as age and gender)</p></li><li class="li"><p>Change the voice used for spoken output</p></li><li class="li"><p>Determine if another application is currently speaking</p></li><li class="li"><p>Start and stop speech</p></li><li class="li"><p>Manage delegates</p></li></ul><p>To make your application speak a word or phrase, you use an instance method to send text to your <code>NSSpeechSynthesizer</code> object (alternatively, you can use an instance method to cause the sound output to be saved to a file). Using the delegate methods defined by the <code>NSSpeechSynthesizer</code> class, you can also perform application-specific actions just before a word or phoneme is spoken or just after the synthesizer finishes speaking a string. You might use these methods to, for example, change the state of a start/stop speaking button or to synchronize the animation of a character’s mouth with the spoken output.</p><p>Although you can use a class method to get the attributes for a specific voice, the <code>NSSpeechSynthesizer</code> class does not define methods that allow you to get or change the attributes of a speech channel. In addition, the <code>NSSpeechSynthesizer</code> class does not support the programmatic conversion of text to phonemes. To do these things, you must use functions in the Carbon speech synthesis API.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW6" title="Overview of the Carbon Speech Synthesis API"></a><h3>Overview of the Carbon Speech Synthesis API</h3><p>The Carbon speech synthesis API (also called the Speech Synthesis Manager) includes functions that allow you to:</p><ul class="spaceabove"><li class="li"><p>Create and manage speech channels</p></li><li class="li"><p>Adjust speech attributes on a speech channel</p></li><li class="li"><p>Convert text to phonemes</p></li><li class="li"><p>Get information about speech channels and voices</p></li><li class="li"><p>Start, stop, and pause speech</p></li><li class="li"><p>Create, invoke, and dispose of universal procedure pointers that point to functions you supply to synchronize speech with application-specific actions</p></li></ul><p>In addition to these functions, the Carbon speech synthesis API defines constants that describe voice and speech-channel attributes, data types (such as phoneme and voice description structures), and a large number of selectors that operate on speech channels.</p><p>Even though the Carbon speech synthesis API is not object-oriented, it may help to think of a speech channel (a structure of type <code><!--a target="_top" -->SpeechChannel<!--/a--></code>) as analogous to an instance of the <code>NSSpeechSynthesizer</code> class. This is because a speech channel is the primary conduit between your application and the Speech Synthesis framework, and you must create one to perform most speech-related tasks, such as getting information about a voice, sending text to be spoken, or adjusting speech attributes. The one exception to this is the <code><a href="../../../../Carbon/Reference/Speech_Synthesis_Manager/Reference/reference.html#//apple_ref/c/func/SpeakString" target="_top">SpeakString</a></code> function, which does not require you to create a speech channel. When you pass a string to the <code><a href="../../../../Carbon/Reference/Speech_Synthesis_Manager/Reference/reference.html#//apple_ref/doc/c_ref/SpeakString" target="_top">SpeakString</a></code> function, the Speech Synthesis Manager automatically creates and manages the structures required to speak.</p><p>Using selectors that you can pass to the <code><a href="../../../../Carbon/Reference/Speech_Synthesis_Manager/Reference/reference.html#//apple_ref/c/func/SetSpeechInfo" target="_top">SetSpeechInfo</a></code> function, you can replicate some of the functionality you get when you use embedded speech commands. For example, you can change the input-processing mode on the speech channel by passing the <code>soInputMode</code> selector. This has the same effect as the <code>[[inpt &lt;mode>]]</code> embedded speech command, except that it operates on the speech channel as a whole, not on a portion of the text. <span class="content_text"><a href="../FineTuning/FineTuning.html#//apple_ref/doc/uid/TP40004365-CH5-SW6">Table 3-1</a></span> pairs each embedded speech command with its analogous selector, if one exists. Other selectors allow you to set speech channel attributes or to associate a callback function with a speech channel. See <em><a href="../../../../Carbon/Reference/Speech_Synthesis_Manager/index.html#//apple_ref/doc/uid/TP30000211" target="_top">Speech Synthesis Manager Reference</a></em> for a complete list of available selectors.</p><p></p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW8" title="Implementing Basic Speech Synthesis Tasks Using Cocoa and Carbon"></a><h2>Implementing Basic Speech Synthesis Tasks Using Cocoa and Carbon</h2><p>This section describes how to use the Cocoa and Carbon APIs to perform basic set-up tasks, such as getting a speech channel, designating a specific voice, starting and stopping speech, and responding to speech events. </p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW11" title="Generating Speech Using the Cocoa Speech Synthesis API"></a><h3>Generating Speech Using the Cocoa Speech Synthesis API</h3><p>To generate speech using the Cocoa speech synthesis API, you must instantiate an <code>NSSpeechSynthesizer</code> object and send to it the text to speak. The code in <span class="content_text">Listing 2-1</span> shows how to use this object to get information about available voices and how to respond to some speech events. This code is a simplified version of the NSSpeechSynthesizerExample example project located in <code>/Developer/Examples/Speech/Synthesis</code>. The code in <span class="content_text">Listing 2-1</span> does not show how to create a pop-up menu of available voices or manage text selection and it does not implement any error handling.</p><p>The code in <span class="content_text">Listing 2-1</span> shows an implementation of an <code>NSObject</code> subclass called <code>ExampleWindow</code>. It uses a simple window that contains the following items:</p><ul class="spaceabove"><li class="li"><p>A text view (declared as <code>NSTextView * _textView</code>) that displays the text to be spoken</p></li><li class="li"><p>A pop-up menu (declared as <code>NSPopUpButton * _voicePop</code>) that displays the available voices from which the user can choose</p></li><li class="li"><p>A button (declared as <code>NSButton * _speakButton</code>) the user clicks to start and stop speech</p></li></ul><a name="//apple_ref/doc/uid/TP40004365-CH4-SW5" title="Listing 2-1Generating speech using the Cocoa speech synthesis API"></a><p class="codesample"><strong>Listing 2-1&nbsp;&nbsp;</strong>Generating speech using the Cocoa speech synthesis API</p><div class="codesample"><table><tr><td scope="row"><pre>@implementation ExampleWindow<span></span></pre></td></tr><tr><td scope="row"><pre>/* Instantiate an NSSpeechSynthesizer object when the application starts */<span></span></pre></td></tr><tr><td scope="row"><pre>- (void)awakeFromNib<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    _speechSynthesizer  = [NSSpeechSynthesizer new];<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Make the ExampleWindow object the responder to NSSpeechSynthesizer delegate methods */<span></span></pre></td></tr><tr><td scope="row"><pre>    [_speechSynthesizer setDelegate:self];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Call a custom method to populate the pop-up menu of available voices (implementation not shown) */<span></span></pre></td></tr><tr><td scope="row"><pre>    [self getSpeechVoices];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>/* When the user clicks the Start Speaking button, invoke the custom startSpeakingTextView method to retrieve (or create) the text and speak it */<span></span></pre></td></tr><tr><td scope="row"><pre>- (IBAction) speakTextButtonSelected:(id)sender<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>  [self startSpeakingTextView];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>- (void)startSpeakingTextView<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    if([_speechSynthesizer isSpeaking]) {<span></span></pre></td></tr><tr><td scope="row"><pre>        [_speechSynthesizer stopSpeaking];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>    else {<span></span></pre></td></tr><tr><td scope="row"><pre>         NSString *    theViewText;<span></span></pre></td></tr><tr><td scope="row"><pre>        /* If the user chooses to hear the default system voice, get the text to speak from the window (either the default text or user-supplied) */<span></span></pre></td></tr><tr><td scope="row"><pre>        if ([_voicePop indexOfSelectedItem] == 0) {<span></span></pre></td></tr><tr><td scope="row"><pre>            [_speechSynthesizer setVoice:NULL];<span></span></pre></td></tr><tr><td scope="row"><pre>            theViewText = [_textView string];<span></span></pre></td></tr><tr><td scope="row"><pre>        }<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Otherwise, get the user's chosen voice, create a string using the voice's demo text, and speak it */<span></span></pre></td></tr><tr><td scope="row"><pre>        else {<span></span></pre></td></tr><tr><td scope="row"><pre>            [_speechSynthesizer setVoice:[[NSSpeechSynthesizer availableVoices] objectAtIndex:[_voicePop indexOfSelectedItem] - kNumOfFixedMenuItemsInVoicePopup]];<span></span></pre></td></tr><tr><td scope="row"><pre>            /* Get the attributes of the chosen voice */<span></span></pre></td></tr><tr><td scope="row"><pre>            NSDictionary * attributes = [NSSpeechSynthesizer attributesForVoice:[_speechSynthesizer voice]];<span></span></pre></td></tr><tr><td scope="row"><pre>            /* Get the value of the voice's name attribute */<span></span></pre></td></tr><tr><td scope="row"><pre>            NSString * theName = [attributes objectForKey:NSVoiceName];<span></span></pre></td></tr><tr><td scope="row"><pre>            /* Build a string using the voice's name and demo text in this format: "This is &lt;name>. &lt;Demo text.>" */<span></span></pre></td></tr><tr><td scope="row"><pre>            theViewText = [NSString stringWithFormat:@"This is %@. %@", theName,[attributes objectForKey:NSVoiceDemoText]];<span></span></pre></td></tr><tr><td scope="row"><pre>            /* Display this new string in the window */<span></span></pre></td></tr><tr><td scope="row"><pre>            [_textView setString:theViewText];<span></span></pre></td></tr><tr><td scope="row"><pre>         }<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Send string to synthesizer object */<span></span></pre></td></tr><tr><td scope="row"><pre>        [_speechSynthesizer startSpeakingString:theViewText];<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Change button name to reflect current state */<span></span></pre></td></tr><tr><td scope="row"><pre>        [_speakButton setTitle:@"Stop Speaking"];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre>@end<span></span></pre></td></tr></table></div>	<p>As shown in the <code>awakeFromNib</code> method in <span class="content_text">Listing 2-1</span>, the <code>ExampleWindow</code> object will respond to delegate methods defined by the <code>NSSpeechSynthesizer</code> class. <span class="content_text">Listing 2-2</span> includes example implementations of two of these methods, showing how to perform application-specific actions that are synchronized with speech events.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW7" title="Listing 2-2Using delegate methods to respond to speech events"></a><p class="codesample"><strong>Listing 2-2&nbsp;&nbsp;</strong>Using delegate methods to respond to speech events</p><div class="codesample"><table><tr><td scope="row"><pre>/* This delegate method is invoked when the NSSpeechSynthesizer object has finished speaking. This happens when there is no more text to speak or when the user clicks the Stop Speaking button. */<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>- (void)speechSynthesizer:(NSSpeechSynthesizer *)sender didFinishSpeaking:(BOOL)finishedSpeaking<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Return cursor to beginning of line */<span></span></pre></td></tr><tr><td scope="row"><pre>    [_textView setSelectedRange:NSMakeRange(0,0)];<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Reset button title to initial string */<span></span></pre></td></tr><tr><td scope="row"><pre>    [_speakButton setTitle:@"Start Speaking")];<span></span></pre></td></tr><tr><td scope="row"><pre>    [_speakButton setEnabled:YES];<span></span></pre></td></tr><tr><td scope="row"><pre>    [_voicePop setEnabled:YES];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>/* This delegate method is called when a word (defined by its character range within the string) is about to be spoken. This implementation uses this information to highlight each word as it's being spoken. */<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>- (void)speechSynthesizer:(NSSpeechSynthesizer *)sender willSpeakWord:(NSRange)characterRange ofString:(NSString *)string<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32    selectionPosition = characterRange.location;<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32    wordLength = characterRange.length;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    [_textView scrollRangeToVisible:NSMakeRange(selectionPosition, wordLength)];<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Highlight word about to be spoken */<span></span></pre></td></tr><tr><td scope="row"><pre>    [_textView setSelectedRange:NSMakeRange(selectionPosition, wordLength)];<span></span></pre></td></tr><tr><td scope="row"><pre>    [_textView display];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_21" title="Generating Speech Using the Carbon Speech Synthesis API"></a><h3>Generating Speech Using the Carbon Speech Synthesis API</h3><p>To generate speech using the Carbon speech synthesis API, you must create a speech channel and send to it the text to speak. The example code in this section is modeled on the CocoaSpeechSynthesisExample example project (located in <code>/Developer/Examples/Speech/Synthesis</code>), which shows how to use the Carbon speech synthesis API within a Cocoa application. Much of the example application’s infrastructure is provided by Cocoa’s <code><a href="../../../../Cocoa/Reference/ApplicationKit/Classes/NSDocument_Class/Reference/Reference.html#//apple_ref/occ/cl/NSDocument" target="_top">NSDocument</a></code> class and the code that displays and manages the window and its contents is not reproduced in the following code listings. The code in the listings below shows how to use a handful of the Carbon speech synthesis functions; see the CocoaSpeechSynthesisExample application for a broader sampling. </p><p>The code in <span class="content_text">Listing 2-3</span> shows a partial implementation of an  <code>NSDocument</code> subclass, called <code>SpeakingTextWindow</code>. <code>SpeakingWindow</code> contains the following instance variables:</p><ul class="spaceabove"><li class="li"><p><code>fCurSpeechChannel</code> (of type <code>SpeechChannel</code>) to point to the current speech channel</p></li><li class="li"><p><code>fCurrentlySpeaking</code> (of type <code>BOOL</code>) to indicate the current speech state</p></li></ul><a name="//apple_ref/doc/uid/TP40004365-CH4-SW10" title="Listing 2-3Generating speech using the Carbon speech synthesis API"></a><p class="codesample"><strong>Listing 2-3&nbsp;&nbsp;</strong>Generating speech using the Carbon speech synthesis API</p><div class="codesample"><table><tr><td scope="row"><pre>/* Callback function prototype: */<span></span></pre></td></tr><tr><td scope="row"><pre>static pascal void     MyWordCallBackProc(SpeechChannel inSpeechChannel, long inRefCon, long inWordPos, short inWordLen);<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>@implementation SpeakingTextWindow<span></span></pre></td></tr><tr><td scope="row"><pre>- (void)awakeFromNib<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    OSErr        theErr = noErr;<span></span></pre></td></tr><tr><td scope="row"><pre>    short        numOfVoices;<span></span></pre></td></tr><tr><td scope="row"><pre>    long         voiceIndex;<span></span></pre></td></tr><tr><td scope="row"><pre>    BOOL        voiceFoundAndSelected = false;<span></span></pre></td></tr><tr><td scope="row"><pre>    VoiceSpec    theVoiceSpec; /* VoiceSpec is a structure that contains the identity of the synthesizer required to use a voice and the ID of a voice. */<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Get the number of voices on the system. Note that you do not need to get a speech channel to get information about available voices. */<span></span></pre></td></tr><tr><td scope="row"><pre>    theErr = CountVoices(&amp;numOfVoices); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    for (voiceIndex = 1; voiceIndex &lt;= numOfVoices; voiceIndex++) {<span></span></pre></td></tr><tr><td scope="row"><pre>        VoiceDescription    theVoiceDesc;<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Get the VoiceSpec structure for this voice. The structure fields will be filled in by a call to GetVoiceDescription. */<span></span></pre></td></tr><tr><td scope="row"><pre>        theErr = GetIndVoice(voiceIndex, &amp;theVoiceSpec); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>        /* Fill in the fields of the theVoiceDesc VoiceDescription structure. */<span></span></pre></td></tr><tr><td scope="row"><pre>        theErr = GetVoiceDescription(&amp;theVoiceSpec, &amp;theVoiceDesc, sizeof(theVoiceDesc)); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>        /* Add this voice name to the pop-up menu (not shown). */<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* If a speech channel already exists, dispose of it. */<span></span></pre></td></tr><tr><td scope="row"><pre>    if (fCurSpeechChannel) {<span></span></pre></td></tr><tr><td scope="row"><pre>        theErr = DisposeSpeechChannel(fCurSpeechChannel); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre>        fCurSpeechChannel = NULL;<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Create a speech channel. */<span></span></pre></td></tr><tr><td scope="row"><pre>    theErr = NewSpeechChannel(NULL, &amp;fCurSpeechChannel); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Set the refcon to the document controller object to ensure that the callback functions have access to it. */<span></span></pre></td></tr><tr><td scope="row"><pre>    theErr = SetSpeechInfo(fCurSpeechChannel, soRefCon, (Ptr)self); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Enable the Start/Stop and Pause/Continue buttons (not shown). */<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>- (IBAction)startStopButtonPressed:(id)sender<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    /* This action method is called when a user clicks the Start/Stop speaking button. */<span></span></pre></td></tr><tr><td scope="row"><pre>    OSErr theErr = noErr;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    if (fCurrentlySpeaking) {<span></span></pre></td></tr><tr><td scope="row"><pre>        /* If speech is currently being produced, stop it immediately. Alternatively, you could use the StopSpeechAt function to stop the speech at the end of a word or sentence.*/<span></span></pre></td></tr><tr><td scope="row"><pre>        theErr = StopSpeech(fCurSpeechChannel); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre>        fCurrentlySpeaking = false;<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Update the controls, based on current speaking state (the updateSpeakingControlState method is not shown). */<span></span></pre></td></tr><tr><td scope="row"><pre>        [self updateSpeakingControlState];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>    else {<span></span></pre></td></tr><tr><td scope="row"><pre>        /* Call the method that sets up the callbacks on the speech channel and sends the text to be spoken. */<span></span></pre></td></tr><tr><td scope="row"><pre>        [self startSpeakingTextView];<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>- (void)startSpeakingTextView<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    /* This method sets up a callback that gets called when a word has been spoken. It also starts spoken output by calling the SpeakText function. */<span></span></pre></td></tr><tr><td scope="row"><pre>    OSErr theErr = noErr;<span></span></pre></td></tr><tr><td scope="row"><pre>    NSString * theViewText;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Get the text from the window and store in theViewText (not shown). */<span></span></pre></td></tr><tr><td scope="row"><pre>    /* Set up the word callback function. Other callback functions can be set up in a similar way. */<span></span></pre></td></tr><tr><td scope="row"><pre>    theErr = SetSpeechInfo(fCurSpeechChannel, soSpeechDoneCallBack, MySpeechDoneCallBackProc); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Convert the theViewText NSString object to a C string variable.*/<span></span></pre></td></tr><tr><td scope="row"><pre>    char * theTextToSpeak = (char *)[theViewText lossyCString];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Send the text to the speech channel. */<span></span></pre></td></tr><tr><td scope="row"><pre>    theErr = SpeakText(fCurSpeechChannel, theTextToSpeak, strlen(theTextToSpeak)); // Handle error if necessary.<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Update variables and control states (you might want to define other variables to hold the current pause state and the most recent error code). */<span></span></pre></td></tr><tr><td scope="row"><pre>    fCurrentlySpeaking = true;<span></span></pre></td></tr><tr><td scope="row"><pre>    [self updateSpeakingControlState];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>As shown in <span class="content_text">Listing 2-3</span>, the <code>startSpeakingTextView</code> method sets up a callback procedure on the speech channel. The CocoaSpeechSynthesisExample example application uses the callback procedure to call a function that highlights each word in the text as it’s spoken. </p><p>The code in <span class="content_text">Listing 2-4</span> shows the callback procedure, which uses the <code>NSObject</code> method <code><a href="../../../../Cocoa/Reference/Foundation/Classes/NSObject_Class/Reference/Reference.html#//apple_ref/occ/instm/NSObject/performSelectorOnMainThread:withObject:waitUntilDone:" target="_top">performSelectorOnMainThread:withObject:waitUntilDone:</a></code> to call the routine that actually performs the processing associated with the callback. The reason <code>MyWordCallBackProc</code> doesn’t perform the word highlighting itself is that all Carbon speech synthesis callbacks (except <code><!--a target="_top" -->SpeechTextDoneProcPtr<!--/a--></code>) call their associated functions on a thread other than the main thread. Unless you’ve indicated that your Cocoa application is multithreaded, this can cause problems if your callback routine touches the user interface or other application objects. To avoid these problems, use the <code>performSelectorOnMainThread:withObject:waitUntilDone:</code> method to ensure your callback processing routine is called on the main thread. Of course, this mechanism is unnecessary in a pure Carbon application.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW4" title="Listing 2-4Using a Carbon callback procedure to respond to a speech event"></a><p class="codesample"><strong>Listing 2-4&nbsp;&nbsp;</strong>Using a Carbon callback procedure to respond to a speech event</p><div class="codesample"><table><tr><td scope="row"><pre>pascal void MyWordCallBackProc(SpeechChannel inSpeechChannel, long inRefCon, long inWordPos, short inWordLen)<span></span></pre></td></tr><tr><td scope="row"><pre>{<span></span></pre></td></tr><tr><td scope="row"><pre>    NSAutoreleasePool *    pool = [[NSAutoreleasePool alloc] init];<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    /* Call the highlightWordWithParams: method to highlight each word as it's spoken. highlightWordWithParams (not shown) receives a dictionary containing two values: the number of bytes between the beginning of the text and the beginning of the word about to be spoken and the length in bytes of that word. */<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    [(SpeakingTextWindow *)inRefCon performSelectorOnMainThread:@selector(highlightWordWithParams:) withObject:[NSDictionary dictionaryWithObjectsAndKeys:[NSNumber numberWithLong:inWordPos], kWordCallbackParamPosition, [NSNumber numberWithLong:inWordLen], kWordCallbackParamLength, NULL] waitUntilDone:false];<span></span></pre></td></tr><tr><td scope="row"><pre>    [pool release];<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>If you’d like to explore making your Cocoa application multithreaded, see <em><a href="../../../../Cocoa/Conceptual/Multithreading/index.html#//apple_ref/doc/uid/10000057i" target="_top">Threading Programming Guide</a></em>. If you’re writing an application similar to CocoaSpeechSynthesisExample and you’d like to make it multithreaded, be sure to include the following line of code before you call any Carbon speech synthesis function for the first time:</p><div class="codesample"><table><tr><td scope="row"><pre>[NSThread detachNewThreadSelector:@selector(self) toTarget:self withObject:nil];<span></span></pre></td></tr></table></div><p>After you’ve used the <code><a href="../../../../Cocoa/Reference/Foundation/Classes/NSThread_Class/Reference/Reference.html#//apple_ref/occ/clm/NSThread/detachNewThreadSelector:toTarget:withObject:" target="_top">detachNewThreadSelector:toTarget:withObject:</a></code> method to create a new thread, you can then perform the callback processing tasks within your callback procedures.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_22" title="Using AppleScript to Produce Spoken Output"></a><h2>Using AppleScript to Produce Spoken Output</h2><p>Using the AppleScript <code>say</code> command, you can cause text to be spoken aloud or saved to a file. The <code>say</code> command is one of the user interaction commands available in the Standard Additions scripting addition (available in <code>/System/Library/ScriptingAdditions</code>). To experiment with the script examples in this section, open the Script Editor application (located in <code>Applications/AppleScript</code>), type the script into the Script Editor window, and click Run.</p><p>The <code>say</code> command speaks the string that follows it (the string can be text enclosed in double quotes or text in a variable). Optionally, you can use the <code>using</code> parameter to tell the <code>say</code> command to use a specific voice and the <code>saving to</code> parameter to redirect the spoken output to an AIFF file. The <code>say</code> command also accepts two parameters that are ignored unless Speech Recognition is turned on. These two parameters (<code>displaying</code> and <code>waiting until completion</code>) are not described in this document. For more information on the syntax and usage of the <code>say</code> command, open <code>StandardAddition.osax</code> in Script Editor.</p><p>The following example uses the Switch to Finder script (located in <code>Applications/AppleScript/Example Scripts/Finder Scripts</code>) to show how you can add the <code>say</code> command to a script to produce spoken output.</p><a name="//apple_ref/doc/uid/TP40004365-CH4-SW9" title="Listing 2-5Using AppleScript to produce spoken output"></a><p class="codesample"><strong>Listing 2-5&nbsp;&nbsp;</strong>Using AppleScript to produce spoken output</p><div class="codesample"><table><tr><td scope="row"><pre>tell application "Finder"
    activate
    set visible of every process whose visible is true and name is not "Finder" to false
    say "To see other application windows again, select Show All from the Finder menu." using "Vicki"
end tell<span></span></pre></td></tr></table></div><p>If you save the spoken output to an AIFF file, you can use it in some other application or listen to it in iTunes (or download it to an iPod). The following example adds a second <code>say</code> command to the script in <span class="content_text">Listing 2-5</span>, this one directing some of the spoken output to a file in the <code>/Users</code> folder. </p><a name="//apple_ref/doc/uid/TP40004365-CH4-DontLinkElementID_47" title="Listing 2-6Using AppleScript to save spoken output to a file"></a><p class="codesample"><strong>Listing 2-6&nbsp;&nbsp;</strong>Using AppleScript to save spoken output to a file</p><div class="codesample"><table><tr><td scope="row"><pre>tell application "Finder"
    activate
    set visible of every process whose visible is true and name is not "Finder" to false
    say "To see other application windows again, select Show All from the Finder menu." using "Vicki"
    say "This is an example of using the AppleScript say command to save spoken output to a file." saving to "Users:AppleScript_speech.aiff"
end tell<span></span></pre></td></tr></table></div>

        <br /><br /> 
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../SpeechOverview/SpeechOverview.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../FineTuning/FineTuning.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCLowerSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <br/><hr /><div align="center"><p class="content_text" lang="en" dir="ltr"> <!--#if expr="0=1" -->&#x00a9; 2006 Apple Computer, Inc. All Rights Reserved. &#40;<!--#endif -->Last updated: 2006-09-05<!--#if expr="0=1" -->&#041;<!--#endif --></p></div>

        
        <div class="hideOnPrint hideInXcode">
        <!-- start of footer -->
        	<table width="100%" border="0" cellpadding="0" cellspacing="0">
		<tr>
			<td><div style="width: 100%; height: 1px; background-color: #919699; margin-top: 5px; margin-bottom: 15px"></div></td>
		</tr>
		<tr>
			<td align="center"><br/>
				<table border="0" cellpadding="0" cellspacing="0" class="graybox">
					<tr>
						<th>Did this document help you?</th>
					</tr>
					<tr>
						<td>
						    <div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=1&url=/documentation/UserExperience/Conceptual/SpeechSynthesisProgrammingGuide/UsingSpeech/UsingSpeech.html%3Fid%3DTP40004365-1.0&media=dvd" target=_new>Yes</a>:  Tell us what works for you.</div>
							<div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=2&url=/documentation/UserExperience/Conceptual/SpeechSynthesisProgrammingGuide/UsingSpeech/UsingSpeech.html%3Fid%3DTP40004365-1.0&media=dvd" target=_new>It&#8217;s good, but:</a> Report typos, inaccuracies, and so forth.</div>
							<div><a href="http://developer.apple.com/feedback/?v=3&url=/documentation/UserExperience/Conceptual/SpeechSynthesisProgrammingGuide/UsingSpeech/UsingSpeech.html%3Fid%3DTP40004365-1.0&media=dvd" target=_new>It wasn&#8217;t helpful</a>: Tell us what would have helped.</div>
						</td>
					</tr>
				</table>
			</td>
		</tr>
	</table>

        <!--#include virtual="/includes/framesetfooter" -->
        <!-- end of footer -->
        </div>
    </div>
</body>
</html>