<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>Audio Queue Services Programming Guide: About Audio Queues</title>
	<meta id="Generator" name="Generator" content="Gutenberg"/>
	<meta id="GeneratorVersion" name="GeneratorVersion" content="v132"/>
	<meta http-equiv="content-type" content="text/html;charset=utf-8"/>
	<meta id="Copyright" name="Copyright" content="Copyright 2009 Apple Inc. All Rights Reserved."/>
	<meta id="IndexTitle" name="IndexTitle" content="About Audio Queues"/>
	<meta id="xcode-display" name="xcode-display" content="render"/>
	<meta id="toc-file" name="toc-file" content="../toc.html"/>
	<meta id="RESOURCES" content="../../../../Resources" />
	
	<link rel="stylesheet" type="text/css" href="../../../../Resources/CSS/frameset_styles.css"/>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/prototype.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/scriptaculous.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/page.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/pedia.js"></script>
	<!--[if lte IE 6]>
		<style type="text/css">
			/*<![CDATA[*/ 
			html {overflow-x:auto; overflow-y:hidden;  }
			/*]]>*/
		</style>
	<![endif]-->
</head>    
<body bgcolor="#ffffff" onload="initialize_page();"><a name="//apple_ref/doc/uid/TP40005343-CH5" title="About Audio Queues"></a>
    <noscript>
    <div id="tocMenu">
        <iframe id="toc_content" name="toc_content" SRC="../toc.html" width="210" height="100%" align="left" frameborder="0">This document set is best viewed in a browser that supports iFrames.</iframe>
    </div>
    </noscript>
    <div id="bodyText">
        <a name="top"></a>
        <div class="hideOnPrint hideInXcode">
        <!-- start of header -->
        <!--#include virtual="/includes/framesetheader" -->
        <!-- end of header -->
        </div>
        
        <!-- start of path -->
<div class="breadcrumb hideOnPrint hideInXcode"><a href="http://developer.apple.com/" target="_top">ADC Home</a> &gt; <a href="../../../../../referencelibrary/index.html#//apple_ref/doc/uid/TP30000943" target="_top">Reference Library</a> &gt; <a href="../../../../index.html#//apple_ref/doc/uid/TP30000440" target="_top">Guides</a> &gt; <a href="../../../index.html#//apple_ref/doc/uid/TP30000440-TP30000428" target="_top">Audio</a> &gt; <a href="../../../CoreAudio-date.html#//apple_ref/doc/uid/TP30000440-TP30000428-TP30000500" target="_top">Core Audio</a> &gt; <a href="../Introduction/Introduction.html#//apple_ref/doc/uid/TP40005343-CH1-SW1">Audio Queue Services Programming Guide</a> &gt; </div><br class="hideInXcode"/><!-- end of path -->
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../Introduction/Introduction.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../AQRecord/RecordingAudio.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCUpperSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" hideText="Hide TOC" showText="Show TOC" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <hr />
        
        
        <a name="//apple_ref/doc/uid/TP40005343-CH5-SW1" title="About Audio Queues"></a><h1>About Audio Queues</h1><p>In this chapter you learn about the capabilities, architecture, and internal workings of audio queues in Mac OS X. You get introduced to audio queues, audio queue buffers, and the callback functions that audio queues use for recording or playback. You also find out about audio queue states and parameters. By the end of this chapter you will have gained the conceptual understanding you need to use this technology effectively.</p>
<!-- This template is being used for both PDF and HTML. -->

    
    <h4>In this section:</h4>
    
    
    <p class="blockquote">
    
        
			
			
				<a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_20">What Is an Audio Queue?</a>
				
			<br/>
			
        
			
			
				<a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW14">Using Codecs and Audio Data Formats</a>
				
			<br/>
			
        
			
			
				<a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW17">Audio Queue Control and State</a>
				
			<br/>
			
        
			
			
				<a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW15">Audio Queue Parameters</a>
				
			<br/>
			
        

    </p><br/>

<a name="//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_20" title="What Is an Audio Queue?"></a><h2>What Is an Audio Queue?</h2><p>An <strong>audio queue</strong> is a software object you use for recording or playing audio in Mac OS X. It is represented by the <code>AudioQueueRef</code> opaque data type, declared in the <code>AudioQueue.h</code> header file.</p><p>An audio queue does the work of:</p><ul class="ul"><li class="li"><p>Connecting to audio hardware</p></li><li class="li"><p>Managing memory</p></li><li class="li"><p>Employing codecs, as needed, for compressed audio formats</p></li><li class="li"><p>Mediating recording or playback</p></li></ul><p>You can use audio queues with other Core Audio interfaces, and a relatively small amount of custom code, to create a complete digital audio recording or playback solution in your application.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW12" title="Audio Queue Architecture"></a><h3>Audio Queue Architecture</h3><p>All audio queues have the same general structure, consisting of these parts:</p><ul class="spaceabove"><li class="li"><p>A set of <strong>audio queue buffers</strong>, each of which is a temporary repository for some audio data</p></li><li class="li"><p>A <strong>buffer queue</strong>, an ordered list for the audio queue buffers</p></li><li class="li"><p>An <strong>audio queue callback</strong> function, that you write</p></li></ul><p>The architecture varies depending on whether an audio queue is for recording or playback. The differences are in how the audio queue connects its input and output, and in the role of the callback function.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_21" title="Audio Queues for Recording"></a><h4>Audio Queues for Recording</h4><p>A recording audio queue, created with the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueNewInput" target="_top">AudioQueueNewInput</a></code> function, has the structure shown in <span class="content_text">Figure 1-1</span>.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW7" title="Figure 1-1A recording audio queue"></a><p><strong>Figure 1-1&nbsp;&nbsp;</strong>A recording audio queue</p><img src = "../Art/recording_architecture.jpg" alt = "Architecture for a recording audio queue" ></div><br/><p>The input side of a recording audio queue typically connects to external audio hardware, such as a microphone. In the default case, the audio comes from the system’s default audio input device as set by a user in System Preferences.</p><p>The output side of a recording audio queue makes use of a callback function that you write. When recording to disk, the callback writes buffers of new audio data, that it receives from its audio queue, to an audio file. But recording audio queues are not only for writing to files. You could also use one, for example, in a realtime audio analyzer. In such a case, your callback would provide audio data directly to your application.</p><p>You’ll learn more about this callback in <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW10">“The Recording Audio Queue Callback Function.”</a></span></p><p>Every audio queue—whether for recording or playback—has one or more audio queue buffers. These buffers are arranged in a specific sequence called a buffer queue. In the figure, the audio queue buffers are numbered according to the order in which they are filled—which is the same order in which they are handed off to the callback. You’ll learn how an audio queue uses its buffers in <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW9">“The Buffer Queue and Enqueuing.”</a></span></p><a name="//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_22" title="Audio Queues for Playback"></a><h4>Audio Queues for Playback</h4><p>A playback audio queue (created with the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueNewOutput" target="_top">AudioQueueNewOutput</a></code> function) has the structure shown in <span class="content_text">Figure 1-2</span>.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW8" title="Figure 1-2A playback audio queue"></a><p><strong>Figure 1-2&nbsp;&nbsp;</strong>A playback audio queue</p><img src = "../Art/playback_architecture.jpg" alt = "Architecture for a playback audio queue" ></div><br/><p>In a playback audio queue, the callback is on the input side. The callback is responsible for obtaining audio data from disk (or other source) and handing it off to the audio queue. Playback callbacks also tell their audio queues to stop when there’s no more data to play. You’ll learn more about this callback in <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW11">“The Playback Audio Queue Callback Function.”</a></span></p><p>A playback audio queue’s output typically connects to external audio hardware, such as a loudspeaker. In the default case, the audio goes to the system’s default audio output device as set by a user in System Preferences.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW13" title="Audio Queue Buffers"></a><h3>Audio Queue Buffers</h3><p>An <strong>audio queue buffer</strong> is a data structure, of type <code>AudioQueueBufferRef</code>, as declared in the <code>AudioQueue.h</code> header file:</p><div class="codesample"><table><tr><td scope="row"><pre>typedef struct AudioQueueBuffer {<span></span></pre></td></tr><tr><td scope="row"><pre>    const UInt32   mAudioDataBytesCapacity;<span></span></pre></td></tr><tr><td scope="row"><pre class="bold">    void *const    mAudioData;</pre><pre><span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32         mAudioDataByteSize;<span></span></pre></td></tr><tr><td scope="row"><pre>    void           *mUserData;<span></span></pre></td></tr><tr><td scope="row"><pre>} AudioQueueBuffer;<span></span></pre></td></tr><tr><td scope="row"><pre>typedef AudioQueueBuffer *AudioQueueBufferRef;<span></span></pre></td></tr></table></div>	<p>The <code>mAudioData</code> field, highlighted in the code listing, points to the buffer per se: a block of memory that serves as a container for transient blocks of audio data being played or recorded. The information in the other fields helps an audio queue manage the buffer.</p><p>An audio queue can use any number of buffers—your application specifies how many. A typical number is three. This allows one to be busy with, say, writing to disk while another is being filled with fresh audio data. The third buffer is available if needed to compensate for such things as disk I/O delays. <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW2">Figure 1-3</a></span> illustrates this.</p><p>Audio queues perform all memory management for their buffers. This helps improve the robustness of the recording and playback features you add to your application. It also helps optimize resource usage.</p><p>For a complete description of the <code>AudioQueueBuffer</code> data structure, see <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em>.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW9" title="The Buffer Queue and Enqueuing"></a><h3>The Buffer Queue and Enqueuing</h3><p>The buffer queue is what gives audio queues, and indeed Audio Queue Services, their names. You met the buffer queue—an ordered list of buffers—in <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW12">“Audio Queue Architecture.”</a></span> Here you learn about how the buffer queue is managed in recording and playback. In particular, you learn about <strong>enqueuing</strong>, the addition of an audio queue buffer to a buffer queue. Whether you are implementing recording or playback, enqueuing is a task that your callback must perform.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_23" title="The Recording Process"></a><h4>The Recording Process</h4><p>When recording, one audio queue buffer is being filled with audio data acquired from an input device, such as a microphone. The remaining buffers in the buffer queue are lined up behind the current buffer, waiting to be filled with audio data in turn.</p><p>The audio queue hands off filled buffers of audio data to your callback in the order in which they were acquired. <span class="content_text">Figure 1-3</span> illustrates how recording works when using an audio queue.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW2" title="Figure 1-3The recording process"></a><p><strong>Figure 1-3&nbsp;&nbsp;</strong>The recording process</p><img src = "../Art/recording_callback_function.jpg" alt = "Illustration of the recording process when using an audio queue" ></div><br/><p>In step 1 of <span class="content_text">Figure 1-3</span>, recording begins. The audio queue fills a buffer with acquired data.</p><p>In step 2, the first buffer has been filled. The audio queue invokes the callback, handing it the full buffer  (buffer 1). The callback (step 3) writes the contents of the buffer to an audio file. At the same time, the audio queue fills another buffer (buffer 2) with freshly acquired data.</p><p>In step 4, the callback enqueues the buffer  (buffer 1) that it has just written to disk, putting it in line to be filled again. The audio queue again invokes the callback (step 5), handing it the next full buffer (buffer 2). The callback (step 6) writes the contents of this buffer to the audio file. This looping steady state continues until the user stops the recording.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-DontLinkElementID_24" title="The Playback Process"></a><h4>The Playback Process</h4><p>When playing, one audio queue buffer is being sent to an output device, such as a loudspeaker. The remaining buffers in the buffer queue are lined up behind the current buffer, waiting to be played in turn.</p><p>The audio queue hands off played buffers of audio data to your callback in the order in which they were played. The callback reads new audio data into a buffer and then enqueues it. <span class="content_text">Figure 1-4</span> illustrates how playback works when using an audio queue.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW3" title="Figure 1-4The playback process"></a><p><strong>Figure 1-4&nbsp;&nbsp;</strong>The playback process</p><img src = "../Art/playback_callback_function.jpg" alt = "Illustration of the playback process when using an audio queue" ></div><br/><p>In step 1 of <span class="content_text">Figure 1-4</span>, the application primes the playback audio queue. The application invokes the callback once for each of the audio queue buffers, filling them and adding them to the buffer queue. Priming ensures that playback can start instantly when your application calls the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStart" target="_top">AudioQueueStart</a></code> function (step 2).</p><p>In step 3, the audio queue sends the first buffer (buffer 1) to output.</p><p>As soon as the first buffer has been played, the playback audio queue enters a looping steady state. The audio queue starts playing the next buffer (buffer 2, step 4) and invokes the callback (step 5), handing it the just-played buffer  (buffer 1). The callback (step 6) fills the buffer from the audio file and then enqueues it for playback.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW16" title="Controlling the Playback Process"></a><h4>Controlling the Playback Process</h4><p>Audio queue buffers are always played in the order in which they are enqueued. However, Audio Queue Services provides you with some control over the playback process with the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBufferWithParameters" target="_top">AudioQueueEnqueueBufferWithParameters</a></code> function. This function lets you:</p><ul class="spaceabove"><li class="li"><p>Set the precise playback time for a buffer. This lets you support synchronization.</p></li><li class="li"><p>Trim frames at the start or end of an audio queue buffer. This lets you remove leading or trailing silence.</p></li><li class="li"><p>Set the playback gain at the granularity of a buffer.</p></li></ul><p>For more about setting playback gain, see <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW15">“Audio Queue Parameters.”</a></span> For a complete description of the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBufferWithParameters" target="_top">AudioQueueEnqueueBufferWithParameters</a></code> function, see <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em>.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW5" title="The Audio Queue Callback Function"></a><h3>The Audio Queue Callback Function</h3><p>Typically, the bulk of your programming work in using Audio Queue Services consists of writing an audio queue callback function.</p><p>During recording or playback, an audio queue callback is invoked repeatedly by the audio queue that owns it. The time between calls depends on the capacity of the audio queue’s buffers and will typically range from half a second to several seconds.</p><p>One responsibility of an audio queue callback, whether it is for recording or playback, is to return audio queue buffers to the buffer queue. The callback adds a buffer to the end of the buffer queue using the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBuffer" target="_top">AudioQueueEnqueueBuffer</a></code> function. For playback, you can instead use the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBufferWithParameters" target="_top">AudioQueueEnqueueBufferWithParameters</a></code> function if you need more control, as described in <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW16">“Controlling the Playback Process.”</a></span></p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW10" title="The Recording Audio Queue Callback Function"></a><h4>The Recording Audio Queue Callback Function</h4><p>This section introduces the callback you’d write for the common case of recording audio to an on-disk file. Here is the prototype for a recording audio queue callback, as declared in the <code>AudioQueue.h</code> header file:</p><div class="codesample"><table><tr><td scope="row"><pre>AudioQueueInputCallback (<span></span></pre></td></tr><tr><td scope="row"><pre>    void                               *inUserData,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                      inAQ,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef                inBuffer,<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioTimeStamp               *inStartTime,<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                             inNumberPacketDescriptions,<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioStreamPacketDescription *inPacketDescs<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>A recording audio queue, in invoking your callback, supplies everything the callback needs to write the next set of audio data to the audio file:</p><ul class="spaceabove"><li class="li"><p><em>inUserData</em> is, typically, a custom structure that you’ve set up to contain state information for the audio queue and its buffers, an audio file object (of type <code>AudioFileID</code>) representing the file you’re writing to, and audio data format information for the file.</p></li><li class="li"><p><em>inAQ</em> is the audio queue that invoked the callback.</p></li><li class="li"><p><em>inBuffer</em> is an audio queue buffer, freshly filled by the audio queue, containing the new data your callback needs to write to disk. The data is already formatted according to the format you specify in the custom structure (passed in the <em>inUserData</em> parameter). For more on this, see <span class="content_text"><a href="AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW14">“Using Codecs and Audio Data Formats.”</a></span></p></li><li class="li"><p><em>inStartTime</em> is the sample time of the first sample in the buffer. For basic recording, your callback doesn’t use this parameter.</p></li><li class="li"><p><em>inNumberPacketDescriptions</em> is the number of packet descriptions in the <code>inPacketDescs</code> parameter. If you are recording to a VBR (variable bitrate) format, the audio queue supplies a value for this parameter to your callback, which in turn passes it on to the <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileWritePackets" target="_top">AudioFileWritePackets</a></code> function. CBR (constant bitrate) formats don’t use packet descriptions. For a CBR recording, the audio queue sets this and the <em>inPacketDescs</em> parameter to <code>NULL</code>.</p></li><li class="li"><p><em>inPacketDescs</em> is the set of packet descriptions corresponding to the samples in the buffer. Again, the audio queue supplies the value for this parameter, if the audio data is in a VBR format, and your callback passes it on to the <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileWritePackets" target="_top">AudioFileWritePackets</a></code> function (declared in the <code>AudioFile.h</code> header file).</p></li></ul><p>For more information on the recording callback, see <span class="content_text"><a href="../AQRecord/RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW1">“Recording Audio”</a></span> in this document, and see <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em>.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW11" title="The Playback Audio Queue Callback Function"></a><h4>The Playback Audio Queue Callback Function</h4><p>This section introduces the callback you’d write for the common case of playing audio from an on-disk file. Here is the prototype for a playback audio queue callback, as declared in the <code>AudioQueue.h</code> header file:</p><div class="codesample"><table><tr><td scope="row"><pre>AudioQueueOutputCallback (<span></span></pre></td></tr><tr><td scope="row"><pre>    void                  *inUserData,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef         inAQ,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef   inBuffer<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>A playback audio queue, in invoking your callback, supplies what the callback needs to read the next set of audio data from the audio file:</p><ul class="spaceabove"><li class="li"><p><em>inUserData</em> is, typically, a custom structure that you’ve set up to contain state information for the audio queue and its buffers, an audio file object (of type <code>AudioFileID</code>) representing the file you’re writing to, and audio data format information for the file.</p><p>In the case of a playback audio queue, your callback keeps track of the current packet index using a field in this structure.</p></li><li class="li"><p><em>inAQ</em> is the audio queue that invoked the callback.</p></li><li class="li"><p><em>inBuffer</em> is an audio queue buffer, made available by the audio queue, that your callback is to fill with the next set of data read from the file being played.</p></li></ul><p>If your application is playing back VBR data, the callback needs to get the packet information for the audio data it’s reading. It does this by calling the <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileReadPackets" target="_top">AudioFileReadPackets</a></code> function, declared in the <code>AudioFile.h</code> header file. The callback then places the packet information in the custom data structure to make it available to the playback audio queue.</p><p>For more information on the playback callback, see <span class="content_text"><a href="../AQPlayback/PlayingAudio.html#//apple_ref/doc/uid/TP40005343-CH3-SW1">“Playing Audio”</a></span> in this document, and see <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em>.</p><!-- <Section XRefSourceID="SW13"><Name>The Audio Queue Client/Server Model</Name><Para>Audio Queue Services is built on a client/server model, in which your application is the client of an audio queue. This confers two advantages to your application:</Para><List-Bullet><Item><Para>The audio queue’s execution thread is automatically independent of your application’s user interface thread, ensuring that user interaction does not cause glitches in recording or playback.</Para></Item><Item><Para>Because the audio queue runs in a separate process, the footprint of the audio stack for your applications is reduced.</Para></Item></List-Bullet></Section> --><a name="//apple_ref/doc/uid/TP40005343-CH5-SW14" title="Using Codecs and Audio Data Formats"></a><h2>Using Codecs and Audio Data Formats</h2><p>Audio Queue Services employs codecs (audio data coding/decoding components) as needed for converting between audio formats. Your recording or playback application can use any audio format for which there is an installed codec. You do not need to write custom code to handle various audio formats. Specifically, your callback does not need to know about data formats.</p><p>Here’s how this works. Each audio queue has an audio data format, represented in an <code>AudioStreamBasicDescription</code> structure. When you specify the format—in the <code>mFormatID</code> field of the structure—the audio queue uses the appropriate codec. You then specify sample rate and channel count, and that’s all there is to it. You'll see examples of setting audio data format in <span class="content_text"><a href="../AQRecord/RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW1">“Recording Audio”</a></span> and <span class="content_text"><a href="../AQPlayback/PlayingAudio.html#//apple_ref/doc/uid/TP40005343-CH3-SW1">“Playing Audio.”</a></span></p><p>A recording audio queue makes use of an installed codec as shown in <span class="content_text">Figure 1-5</span>.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW4" title="Figure 1-5Audio format conversion during recording"></a><p><strong>Figure 1-5&nbsp;&nbsp;</strong>Audio format conversion during recording</p><img src = "../Art/recording_codec.jpg" alt = "Using a code when recording with an audio queue" ></div><br/><p>In step 1 of <span class="content_text">Figure 1-5</span>, your application tells an audio queue to start recording, and also tells it the data format to use. In step 2, the audio queue obtains new audio data and converts it, using a codec, according to the format you’ve specified. The audio queue then invokes the callback, handing it a buffer containing appropriately formated audio data. In step 3, your callback writes the formatted audio data to disk. Again, your callback does not need to know about the data formats.</p><p>A playback audio queue makes use of an installed codec as shown in <span class="content_text">Figure 1-6</span>.</p><br/><div><a name="//apple_ref/doc/uid/TP40005343-CH5-SW6" title="Figure 1-6Audio format conversion during playback"></a><p><strong>Figure 1-6&nbsp;&nbsp;</strong>Audio format conversion during playback</p><img src = "../Art/playback_codec.jpg" alt = "Using a codec when playing a file with an audio queue" ></div><br/><p>In step 1 of <span class="content_text">Figure 1-6</span>, your application tells an audio queue to start playing, and also tells it the data format contained in the audio file to be played. In step 2, the audio queue invokes your callback, which reads data from the audio file. The callback hands off the data, in its original format, to the audio queue. In step 3, the audio queue uses the appropriate codec and then sends the audio along to the destination.</p><p>An audio queue can make use of any installed codec, whether native to Mac OS X or provided by a third party. To designate a codec to use, you supply its four-character code ID to an audio queue’s <code>AudioStreamBasicDescription</code> structure. You’ll see an example of this in <span class="content_text"><a href="../AQRecord/RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW1">“Recording Audio.”</a></span></p><p>Mac OS X includes a wide range of audio codecs, as listed in the format IDs enumeration in the <code>CoreAudioTypes.h</code> header file and as documented in <em><a href="../../../Reference/CoreAudioDataTypesRef/index.html#//apple_ref/doc/uid/TP40004488" target="_top">Core Audio Data Types Reference</a></em>. You can determine the codecs available on a system by using the interfaces in the <code>AudioFormat.h</code> header file, in the Audio Toolbox Framework. You can display the codecs on a system using the Fiendishthngs application, available as sample code at <span class="content_text"><a href="../../../../../samplecode/Fiendishthngs/" target="_top">http://developer.apple.com/samplecode/Fiendishthngs/</a></span>.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW17" title="Audio Queue Control and State"></a><h2>Audio Queue Control and State</h2><p>An audio queue has a life cycle between creation and disposal. Your application manages this life cycle—and controls the audio queue’s state—using six functions declared in the <code>AudioQueue.h</code> header file:</p><ul class="ul"><li class="li"><p><strong>Start</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStart" target="_top">AudioQueueStart</a></code>). Call to initiate recording or playback.</p></li><li class="li"><p><strong>Prime</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueuePrime" target="_top">AudioQueuePrime</a></code>). For playback, call before calling <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStart" target="_top">AudioQueueStart</a></code> to ensure that there is data available immediately for the audio queue to play. This function is not relevant to recording.</p></li><li class="li"><p><strong>Stop</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStop" target="_top">AudioQueueStop</a></code>). Call to reset the audio queue (see the description below for  <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueReset" target="_top">AudioQueueReset</a></code>) and to then stop recording or playback. A playback audio queue callback calls this function when there’s no more data to play.</p></li><li class="li"><p><strong>Pause</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueuePause" target="_top">AudioQueuePause</a></code>). Call to pause recording or playback without affecting buffers or resetting the audio queue. To resume, call the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStart" target="_top">AudioQueueStart</a></code> function.</p></li><li class="li"><p><strong>Flush</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueFlush" target="_top">AudioQueueFlush</a></code>). Call after enqueuing the last audio queue buffer to ensure that all buffered data, as well as all audio data in the midst of processing, gets recorded or played.</p></li><li class="li"><p><strong>Reset</strong> (<code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueReset" target="_top">AudioQueueReset</a></code>). Call to immediately silence an audio queue, remove all buffers from previously scheduled use, and reset all decoder and DSP state.</p></li></ul><p>You can use the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStop" target="_top">AudioQueueStop</a></code> function in a synchronous or asynchronous mode:</p><ul class="ul"><li class="li"><p><strong>Synchronous</strong> stopping happens immediately, without regard for previously buffered audio data.</p></li><li class="li"><p><strong>Asynchronous</strong> stopping happens after all queued buffers have been played or recorded.</p></li></ul><p>See <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em> for a complete description of each of these functions, including more information on synchronous and asynchronous stopping of audio queues.</p><a name="//apple_ref/doc/uid/TP40005343-CH5-SW15" title="Audio Queue Parameters"></a><h2>Audio Queue Parameters</h2><p>An audio queue has adjustable settings called <strong>parameters</strong>. Each parameter has an enumeration constant as its key, and a floating-point number as its value. Parameters are typically used in playback, not recording.</p><p>In Mac OS X v10.5, the only audio queue parameter available is for gain. The value for this parameter is set or retrieved using the <code>kAudioQueueParam_Volume</code> constant, and has an available range of <code>0.0</code> for silence, to <code>1.0</code> for unity gain.</p><p>Your application can set audio queue parameters in two ways:</p><ul class="ul"><li class="li"><p>Per audio queue, using the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueSetParameter" target="_top">AudioQueueSetParameter</a></code> function. This lets you change settings for an audio queue directly. Such changes take effect immediately.</p></li><li class="li"><p>Per audio queue buffer, using the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBufferWithParameters" target="_top">AudioQueueEnqueueBufferWithParameters</a></code> function. This lets you assign audio queue settings that are, in effect, carried by an audio queue buffer as you enqueue it. Such changes take effect when the audio queue buffer begins playing. </p></li></ul><p>In both cases, parameter settings for an audio queue remain in effect until you change them.</p><p>You can access an audio queue’s current parameter values at any time with the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueGetParameter" target="_top">AudioQueueGetParameter</a></code> function. See <em><a href="../../../Reference/AudioQueueReference/index.html#//apple_ref/doc/uid/TP40005117" target="_top">Audio Queue Services Reference</a></em> for complete descriptions of the functions for getting and setting parameter values.</p><!-- This stuff should go into Core Audio Overview <Section XRefSourceID="SW4"><Name>Audio Data Formats (move this to Core Audio Overview)</Name><Para>Uncompressed data in buffers is in linear PCM, which contains one frame per packet. The data in the stream is exactly what gets played or recorded.</Para><Para>Some compressed formats compress audio uniformly, so when you stream them for playback, you get the same number of bits per sample played, as shown in <xName-No-Link DestinationChapterID="CH5" Id="SW2" targetElementType="Figure">“CBR format”</xName-No-Link>. These formats are called CBR (constant bit rate).</Para><Figure XRefSourceID="SW2"><Name>CBR format</Name><Graphic href="../Art/cbr.jpg" altDescriptionFor508="CBR Format"></Graphic></Figure><Para>In other compressed formats, the amount of compression varies with the content. Some content compresses better than others, as shown in <xName-No-Link DestinationChapterID="CH5" Id="SW3" targetElementType="Figure">“VBR format”</xName-No-Link>. These formats,  are called VBR (variable bit rate), so you get a variable number of bits per sample played.</Para><Figure XRefSourceID="SW3"><Name>VBR format</Name><Graphic href="../Art/vbr.jpg" altDescriptionFor508="VBR Format"></Graphic></Figure><Para>Compressed audio data must be uncompressed before you can play it. An output audio queue decompresses whatever format has been designated.</Para><Para>When you are recording audio data, an input audio queue converts the data to the format you designated when you created the queue.</Para></Section> -->

        <br /><br /> 
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../Introduction/Introduction.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../AQRecord/RecordingAudio.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCLowerSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <br/><hr /><div align="center"><p class="content_text" lang="en" dir="ltr"> <!--#if expr="0=1" -->&#x00a9; 2007 Apple Inc. All Rights Reserved. &#40;<!--#endif -->Last updated: 2007-10-31<!--#if expr="0=1" -->&#041;<!--#endif --></p></div>

        
        <div class="hideOnPrint hideInXcode">
        <!-- start of footer -->
        	<table width="100%" border="0" cellpadding="0" cellspacing="0">
		<tr>
			<td><div style="width: 100%; height: 1px; background-color: #919699; margin-top: 5px; margin-bottom: 15px"></div></td>
		</tr>
		<tr>
			<td align="center"><br/>
				<table border="0" cellpadding="0" cellspacing="0" class="graybox">
					<tr>
						<th>Did this document help you?</th>
					</tr>
					<tr>
						<td>
						    <div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=1&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AboutAudioQueues/AboutAudioQueues.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>Yes</a>:  Tell us what works for you.</div>
							<div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=2&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AboutAudioQueues/AboutAudioQueues.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>It&#8217;s good, but:</a> Report typos, inaccuracies, and so forth.</div>
							<div><a href="http://developer.apple.com/feedback/?v=3&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AboutAudioQueues/AboutAudioQueues.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>It wasn&#8217;t helpful</a>: Tell us what would have helped.</div>
						</td>
					</tr>
				</table>
			</td>
		</tr>
	</table>

        <!--#include virtual="/includes/framesetfooter" -->
        <!-- end of footer -->
        </div>
    </div>
</body>
</html>