<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
	<title>Audio Queue Services Programming Guide: Recording Audio</title>
	<meta id="Generator" name="Generator" content="Gutenberg"/>
	<meta id="GeneratorVersion" name="GeneratorVersion" content="v132"/>
	<meta http-equiv="content-type" content="text/html;charset=utf-8"/>
	<meta id="Copyright" name="Copyright" content="Copyright 2009 Apple Inc. All Rights Reserved."/>
	<meta id="IndexTitle" name="IndexTitle" content="Recording Audio"/>
	<meta id="xcode-display" name="xcode-display" content="render"/>
	<meta id="toc-file" name="toc-file" content="../toc.html"/>
	<meta id="RESOURCES" content="../../../../Resources" />
	
	<link rel="stylesheet" type="text/css" href="../../../../Resources/CSS/frameset_styles.css"/>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/prototype.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/lib/scriptaculous.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/page.js"></script>
	<script language="JavaScript" type="text/javascript" src="../../../../Resources/JavaScript/pedia.js"></script>
	<!--[if lte IE 6]>
		<style type="text/css">
			/*<![CDATA[*/ 
			html {overflow-x:auto; overflow-y:hidden;  }
			/*]]>*/
		</style>
	<![endif]-->
</head>    
<body bgcolor="#ffffff" onload="initialize_page();"><a name="//apple_ref/doc/uid/TP40005343-CH4" title="Recording Audio"></a>
    <noscript>
    <div id="tocMenu">
        <iframe id="toc_content" name="toc_content" SRC="../toc.html" width="210" height="100%" align="left" frameborder="0">This document set is best viewed in a browser that supports iFrames.</iframe>
    </div>
    </noscript>
    <div id="bodyText">
        <a name="top"></a>
        <div class="hideOnPrint hideInXcode">
        <!-- start of header -->
        <!--#include virtual="/includes/framesetheader" -->
        <!-- end of header -->
        </div>
        
        <!-- start of path -->
<div class="breadcrumb hideOnPrint hideInXcode"><a href="http://developer.apple.com/" target="_top">ADC Home</a> &gt; <a href="../../../../../referencelibrary/index.html#//apple_ref/doc/uid/TP30000943" target="_top">Reference Library</a> &gt; <a href="../../../../index.html#//apple_ref/doc/uid/TP30000440" target="_top">Guides</a> &gt; <a href="../../../index.html#//apple_ref/doc/uid/TP30000440-TP30000428" target="_top">Audio</a> &gt; <a href="../../../CoreAudio-date.html#//apple_ref/doc/uid/TP30000440-TP30000428-TP30000500" target="_top">Core Audio</a> &gt; <a href="../Introduction/Introduction.html#//apple_ref/doc/uid/TP40005343-CH1-SW1">Audio Queue Services Programming Guide</a> &gt; </div><br class="hideInXcode"/><!-- end of path -->
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../AboutAudioQueues/AboutAudioQueues.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../AQPlayback/PlayingAudio.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCUpperSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" hideText="Hide TOC" showText="Show TOC" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <hr />
        
        
        <a name="//apple_ref/doc/uid/TP40005343-CH4-SW1" title="Recording Audio"></a><h1>Recording Audio</h1><p>When you record using Audio Queue Services, the destination can be just about anything—an on-disk file, a network connection, an object in memory, and so on. This chapter describes the most common scenario: basic recording to an on-disk file.</p><div class="notebox"><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_29" title="Note"></a><p><strong>Note:</strong>&nbsp;The code examples in this document are sometimes simplified by using C++ classes from the Core Audio SDK. However, neither the SDK nor the C++ language is necessary to use Audio Queue Services.</p>For additional simplicity, these code examples do not include robust error handling. Make sure to add code to handle potential errors when you implement recording or playback with Audio Queue Services.</p></div><p>To add recording functionality to your application, you typically perform the following steps:</p><ol class="ol"><li class="li"><p>Define a custom structure to manage state, format, and path information.</p></li><li class="li"><p>Write an audio queue callback function to perform the actual recording.</p></li><li class="li"><p>Optionally write code to determine a good size for the audio queue buffers. Write code to work with magic cookies, if you’ll be recording in a format that uses cookies.</p></li><li class="li"><p>Fill the fields of the custom structure. This includes specifying the data stream that the audio queue sends to the file it’s recording into, as well as the path to that file.</p></li><li class="li"><p>Create a recording audio queue and ask it to create a set of audio queue buffers. Also create a file to record into.</p></li><li class="li"><p>Tell the audio queue to start recording.</p></li><li class="li"><p>When done, tell the audio queue to stop and then dispose of it. The audio queue disposes of its buffers.</p></li></ol><p>The remainder of this chapter describes each of these steps in detail.</p>
<!-- This template is being used for both PDF and HTML. -->

    
    <h4>In this section:</h4>
    
    
    <p class="blockquote">
    
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW15">Define a Custom Structure to Manage State</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW24">Write a Recording Audio Queue Callback</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW14">Write a Function to Derive Recording Audio Queue Buffer Size</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_15">Set a Magic Cookie for an Audio File</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">Set Up an Audio Format for Recording</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW2">Create a Recording Audio Queue</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW26">Create an Audio File</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_16">Set an Audio Queue Buffer Size</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_17">Prepare a Set of Audio Queue Buffers</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_18">Record Audio</a>
				
			<br/>
			
        
			
			
				<a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_19">Clean Up After Recording</a>
				
			<br/>
			
        

    </p><br/>

<a name="//apple_ref/doc/uid/TP40005343-CH4-SW15" title="Define a Custom Structure to Manage State"></a><h2>Define a Custom Structure to Manage State</h2><p>The first step in developing a recording solution using Audio Queue Services is to define a custom structure. You’ll use this structure to manage the audio format and audio queue state information. <span class="content_text">Listing 2-1</span> illustrates such a structure:</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW5" title="Listing 2-1A custom structure for a recording audio queue"></a><p class="codesample"><strong>Listing 2-1&nbsp;&nbsp;</strong>A custom structure for a recording audio queue</p><div class="codesample"><table><tr><td scope="row"><pre>static const int kNumberBuffers = 3;                            // 1<span></span></pre></td></tr><tr><td scope="row"><pre>struct AQRecorderState {<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioStreamBasicDescription  mDataFormat;                   // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                mQueue;                        // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef          mBuffers[kNumberBuffers];      // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioFileID                  mAudioFile;                    // 5<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                       bufferByteSize;                // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    SInt64                       mCurrentPacket;                // 7<span></span></pre></td></tr><tr><td scope="row"><pre>    bool                         mIsRunning;                    // 8<span></span></pre></td></tr><tr><td scope="row"><pre>};<span></span></pre></td></tr></table></div>	<p>Here’s a description of the fields in this structure:</p><ol class="ol"><li class="li"><p>Sets the number of audio queue buffers to use.</p></li><li class="li"><p>An <code>AudioStreamBasicDescription</code> structure (from <code>CoreAudioTypes.h</code>) representing the audio data format to write to disk. This format gets used by the audio queue specified in the <code>mQueue</code> field.</p><p>The <code>mDataFormat</code> field gets filled initially by code in your program, as described in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">“Set Up an Audio Format for Recording.”</a></span> It is good practice to then update the value of this field by querying the audio queue's <code>kAudioConverterCurrentOutputStreamDescription</code> property, as described in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW23">“Getting the Full Audio Format from an Audio Queue.”</a></span></p><p>For details on the <code>AudioStreamBasicDescription</code> structure, see <em><a href="../../../Reference/CoreAudioDataTypesRef/index.html#//apple_ref/doc/uid/TP40004488" target="_top">Core Audio Data Types Reference</a></em>.</p></li><li class="li"><p>The recording audio queue created by your application.</p></li><li class="li"><p>An array holding pointers to the audio queue buffers managed by the audio queue.</p></li><li class="li"><p>An audio file object representing the file into which your program records audio data.</p></li><li class="li"><p>The size, in bytes, for each audio queue buffer. This value is calculated in these examples in the <code><!--a-->DeriveBufferSize<!--/a--></code> function, after the audio queue is created and before it is started. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW14">“Write a Function to Derive Recording Audio Queue Buffer Size.”</a></span></p></li><li class="li"><p>The packet index for the first packet to be written from the current audio queue buffer.</p></li><li class="li"><p>A Boolean value indicating whether or not the audio queue is running.</p></li>
 </ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW24" title="Write a Recording Audio Queue Callback"></a><h2>Write a Recording Audio Queue Callback</h2><p>Next, write a recording audio queue callback function. This callback does two main things:</p><ul class="ul"><li class="li"><p>Writes the contents of a newly filled audio queue buffer to the audio file you’re recording into</p></li><li class="li"><p>Enqueues the audio queue buffer (whose contents were just written to disk) to the buffer queue</p></li></ul><p>This section shows an example callback declaration, then describes these two tasks separately, and finally presents an entire recording callback. For an illustration of the role of a recording audio queue callback, you can refer back to <span class="content_text"><a href="../AboutAudioQueues/AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW2">Figure 1-3</a></span>.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_14" title="The Recording Audio Queue Callback Declaration"></a><h3>The Recording Audio Queue Callback Declaration</h3><p><span class="content_text">Listing 2-2</span> shows an example declaration for a recording audio queue callback function, declared as <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueInputCallback" target="_top">AudioQueueInputCallback</a></code> in the <code>AudioQueue.h</code> header file:</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW6" title="Listing 2-2The recording audio queue callback declaration"></a><p class="codesample"><strong>Listing 2-2&nbsp;&nbsp;</strong>The recording audio queue callback declaration</p><div class="codesample"><table><tr><td scope="row"><pre>static void HandleInputBuffer (<span></span></pre></td></tr><tr><td scope="row"><pre>    void                                *aqData,             // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                       inAQ,                // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef                 inBuffer,            // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioTimeStamp                *inStartTime,        // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                              inNumPackets,        // 5<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioStreamPacketDescription  *inPacketDesc        // 6<span></span></pre></td></tr><tr><td scope="row"><pre>)<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>Typically, <code>aqData</code> is a custom structure that contains state data for the audio queue, as described in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW15">“Define a Custom Structure to Manage State.”</a></span></p></li><li class="li"><p>The audio queue that owns this callback.</p></li><li class="li"><p>The audio queue buffer containing the incoming audio data to record.</p></li><li class="li"><p>The sample time of the first sample in the audio queue buffer (not needed for simple recording).</p></li><li class="li"><p>The number of packet descriptions in the inPacketDesc parameter. A value of <code>0</code> indicates CBR data.</p></li><li class="li"><p>For compressed audio data formats that require packet descriptions, the packet descriptions produced by the encoder for the packets in the buffer.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW3" title="Writing an Audio Queue Buffer to Disk"></a><h3>Writing an Audio Queue Buffer to Disk</h3><p>The first task of a recording audio queue callback is to write an audio queue buffer to disk. This buffer is the one the callback’s audio queue has just finished filling with new audio data from an input device. The callback uses the <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileWritePackets" target="_top">AudioFileWritePackets</a></code> function from the <code>AudioFile.h</code> header file, as shown in <span class="content_text">Listing 2-3</span>.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW7" title="Listing 2-3Writing an audio queue buffer to disk"></a><p class="codesample"><strong>Listing 2-3&nbsp;&nbsp;</strong>Writing an audio queue buffer to disk</p><div class="codesample"><table><tr><td scope="row"><pre>AudioFileWritePackets (                                      // 1<span></span></pre></td></tr><tr><td scope="row"><pre>        pAqData->mAudioFile,                                 // 2<span></span></pre></td></tr><tr><td scope="row"><pre>        false,                                               // 3<span></span></pre></td></tr><tr><td scope="row"><pre>        inBuffer->mAudioDataByteSize,                        // 4<span></span></pre></td></tr><tr><td scope="row"><pre>        inPacketDesc,                                        // 5<span></span></pre></td></tr><tr><td scope="row"><pre>        pAqData->mCurrentPacket,                             // 6<span></span></pre></td></tr><tr><td scope="row"><pre>        &amp;inNumPackets,                                       // 7<span></span></pre></td></tr><tr><td scope="row"><pre>        inBuffer->mAudioData                                 // 8<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileWritePackets" target="_top">AudioFileWritePackets</a></code> function, declared in the <code>AudioFile.h</code> header file, writes the contents of a buffer to an audio data file.</p></li><li class="li"><p>The audio file object (of type <code>AudioFileID</code>) that represents the audio file to write to. The <code>pAqData</code> variable is a pointer to the data structure described in <span class="content_text">Listing 2-1</span>.</p></li><li class="li"><p>Uses a value of <code>false</code> to indicate that the function should not cache the data when writing.</p></li><li class="li"><p>The number of bytes of audio data being written. The <code>inBuffer</code> variable represents the audio queue buffer handed to the callback by the audio queue.</p></li><li class="li"><p>An array of packet descriptions for the audio data. A value of <code>NULL</code> indicates no packet descriptions are required (such as for CBR audio data).</p></li><li class="li"><p>The packet index for the first packet to be written.</p></li><li class="li"><p>On input, the number of packets to write. On output, the number of packets actually written.</p></li><li class="li"><p>The new audio data to write to the audio file.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW8" title="Enqueuing an Audio Queue Buffer"></a><h3>Enqueuing an Audio Queue Buffer</h3><p>Now that the audio data from an audio queue buffer has been written to the audio file, the callback enqueues the buffer, as shown in <span class="content_text">Listing 2-4</span>. Once back in the buffer queue, the buffer is in line and ready to accept more incoming audio data.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW10" title="Listing 2-4Enqueuing an audio queue buffer after writing to disk"></a><p class="codesample"><strong>Listing 2-4&nbsp;&nbsp;</strong>Enqueuing an audio queue buffer after writing to disk</p><div class="codesample"><table><tr><td scope="row"><pre>AudioQueueEnqueueBuffer (                                             // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    pAqData->mQueue,                                                  // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    inBuffer,                                                         // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    0,                                                                // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    NULL                                                              // 5<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBuffer" target="_top">AudioQueueEnqueueBuffer</a></code> function adds an audio queue buffer to an audio queue’s buffer queue.</p></li><li class="li"><p>The audio queue to add the designated audio queue buffer to. The <code>pAqData</code> variable is a pointer to the data structure described in <span class="content_text">Listing 2-1</span>.</p></li><li class="li"><p>The audio queue buffer to enqueue.</p></li><li class="li"><p>The number of packet descriptions in the audio queue buffer's data. Set to <code>0</code> because this parameter is unused for recording.</p></li><li class="li"><p>The array of packet descriptions describing the audio queue buffer’s data. Set to <code>NULL</code> because this parameter is unused for recording.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW11" title="A Full Recording Audio Queue Callback"></a><h3>A Full Recording Audio Queue Callback</h3><p><span class="content_text">Listing 2-5</span> shows a basic version of a full recording audio queue callback. As with the rest of the code examples in this document, this listing excludes error handling.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW12" title="Listing 2-5A recording audio queue callback function"></a><p class="codesample"><strong>Listing 2-5&nbsp;&nbsp;</strong>A recording audio queue callback function</p><div class="codesample"><table><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>static void HandleInputBuffer (<span></span></pre></td></tr><tr><td scope="row"><pre>    void                                 *aqData,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                        inAQ,<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueBufferRef                  inBuffer,<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioTimeStamp                 *inStartTime,<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                               inNumPackets,<span></span></pre></td></tr><tr><td scope="row"><pre>    const AudioStreamPacketDescription   *inPacketDesc<span></span></pre></td></tr><tr><td scope="row"><pre>) {<span></span></pre></td></tr><tr><td scope="row"><pre>    AQRecorderState *pAqData = (AQRecorderState *) aqData;               // 1<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    if (inNumPackets == 0 &amp;&amp;                                             // 2<span></span></pre></td></tr><tr><td scope="row"><pre>          pAqData->mDataFormat.mBytesPerPacket != 0)<span></span></pre></td></tr><tr><td scope="row"><pre>       inNumPackets =<span></span></pre></td></tr><tr><td scope="row"><pre>           inBuffer->mAudioDataByteSize / pAqData->mDataFormat.mBytesPerPacket;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    if (AudioFileWritePackets (                                          // 3<span></span></pre></td></tr><tr><td scope="row"><pre>            pAqData->mAudioFile,<span></span></pre></td></tr><tr><td scope="row"><pre>            false,<span></span></pre></td></tr><tr><td scope="row"><pre>            inBuffer->mAudioDataByteSize,<span></span></pre></td></tr><tr><td scope="row"><pre>            inPacketDesc,<span></span></pre></td></tr><tr><td scope="row"><pre>            pAqData->mCurrentPacket,<span></span></pre></td></tr><tr><td scope="row"><pre>            &amp;inNumPackets,<span></span></pre></td></tr><tr><td scope="row"><pre>            inBuffer->mAudioData<span></span></pre></td></tr><tr><td scope="row"><pre>        ) == noErr) {<span></span></pre></td></tr><tr><td scope="row"><pre>            pAqData->mCurrentPacket += inNumPackets;                     // 4<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>   if (pAqData->mIsRunning == 0)                                         // 5<span></span></pre></td></tr><tr><td scope="row"><pre>      return;<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueEnqueueBuffer (                                            // 6<span></span></pre></td></tr><tr><td scope="row"><pre>        pAqData->mQueue,<span></span></pre></td></tr><tr><td scope="row"><pre>        inBuffer,<span></span></pre></td></tr><tr><td scope="row"><pre>        0,<span></span></pre></td></tr><tr><td scope="row"><pre>        NULL<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The custom structure supplied to the audio queue object upon instantiation, including an audio file object representing the audio file to record into as well as a variety of state data. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW15">“Define a Custom Structure to Manage State.”</a></span></p></li><li class="li"><p>If the audio queue buffer contains CBR data, calculate the number of packets in the buffer. This number equals the total bytes of data in the buffer divided by the (constant) number of bytes per packet. For VBR data, the audio queue supplies the number of packets in the buffer when it invokes the callback.</p></li><li class="li"><p>Writes the contents of the buffer to the audio data file. For a detailed description , see <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW3">“Writing an Audio Queue Buffer to Disk.”</a></span></p></li><li class="li"><p>If successful in writing the audio data, increment the audio data file’s packet index to be ready for writing the next buffer's worth of audio data.</p></li><li class="li"><p>If the audio queue has stopped, return.</p></li><li class="li"><p>Enqueues the audio queue buffer whose contents have just been written to the audio file. For a detailed description, see <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW8">“Enqueuing an Audio Queue Buffer.”</a></span></p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW14" title="Write a Function to Derive Recording Audio Queue Buffer Size"></a><h2>Write a Function to Derive Recording Audio Queue Buffer Size</h2><p>Audio Queue Services expects your application to specify a size for the audio queue buffers you use. <span class="content_text">Listing 2-6</span> shows one way to do this. It derives a buffer size large enough to hold a given duration of audio data.</p><p>The calculation here takes into account the audio data format you’re recording to. The format includes all the factors that might affect buffer size, such as the number of audio channels.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW16" title="Listing 2-6Deriving a recording audio queue buffer size"></a><p class="codesample"><strong>Listing 2-6&nbsp;&nbsp;</strong>Deriving a recording audio queue buffer size</p><div class="codesample"><table><tr><td scope="row"><pre>void DeriveBufferSize (<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef                audioQueue,                  // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioStreamBasicDescription  &amp;ASBDescription,             // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    Float64                      seconds,                     // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32                       *outBufferSize               // 4<span></span></pre></td></tr><tr><td scope="row"><pre>) {<span></span></pre></td></tr><tr><td scope="row"><pre>    static const int maxBufferSize = 0x50000;                 // 5<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    int maxPacketSize = ASBDescription.mBytesPerPacket;       // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    if (maxPacketSize == 0) {                                 // 7<span></span></pre></td></tr><tr><td scope="row"><pre>        UInt32 maxVBRPacketSize = sizeof(maxPacketSize);<span></span></pre></td></tr><tr><td scope="row"><pre>        AudioQueueGetProperty (<span></span></pre></td></tr><tr><td scope="row"><pre>                audioQueue,<span></span></pre></td></tr><tr><td scope="row"><pre>                kAudioConverterPropertyMaximumOutputPacketSize,<span></span></pre></td></tr><tr><td scope="row"><pre>                &amp;maxPacketSize,<span></span></pre></td></tr><tr><td scope="row"><pre>                &amp;maxVBRPacketSize<span></span></pre></td></tr><tr><td scope="row"><pre>        );<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    Float64 numBytesForTime =<span></span></pre></td></tr><tr><td scope="row"><pre>        ASBDescription.mSampleRate * maxPacketSize * seconds; // 8<span></span></pre></td></tr><tr><td scope="row"><pre>    *outBufferSize =<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32 (numBytesForTime &lt; maxBufferSize ?<span></span></pre></td></tr><tr><td scope="row"><pre>        numBytesForTime : maxBufferSize);                     // 9<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The audio queue that owns the buffers whose size you want to specify.</p></li><li class="li"><p>The <code>AudioStreamBasicDescription</code> structure for the audio queue.</p></li><li class="li"><p>The size you are specifying for each audio queue buffer, in terms of seconds of audio.</p></li><li class="li"><p>On output, the size for each audio queue buffer, in terms of bytes.</p></li><li class="li"><p>An upper bound for the audio queue buffer size, in bytes. In this example, the upper bound is set to 320 KB. This corresponds to approximately five seconds of stereo, 24 bit audio at a sample rate of 96 kHz.</p></li><li class="li"><p>For CBR audio data, get the (constant) packet size from the <code>AudioStreamBasicDescription</code> structure. Use this value as the maximum packet size.</p><p>This assignment has the side effect of determining if the audio data to be recorded is CBR or VBR. If it is VBR, the audio queue’s <code>AudioStreamBasicDescription</code> structure lists the value of bytes-per-packet as <code>0</code>.</p></li><li class="li"><p>For VBR audio data, query the audio queue to get the estimated maximum packet size.</p></li><li class="li"><p>Derive the buffer size, in bytes.</p></li><li class="li"><p>Limit the buffer size, if needed, to the previously set upper bound.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_15" title="Set a Magic Cookie for an Audio File"></a><h2>Set a Magic Cookie for an Audio File</h2><p>Some compressed audio formats, such as MPEG 4 AAC, make use of structures that contain audio metadata. These structures are called <strong>magic cookies</strong>. When you record to such a format using Audio Queue Services, you must get the magic cookie from the audio queue and add it to the audio file before you start recording.</p><p><span class="content_text">Listing 2-7</span> shows how to obtain a magic cookie from an audio queue and apply it to an audio file. Your code would call a function like this before recording, and then again after recording—some codecs update magic cookie data when recording has stopped.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW13" title="Listing 2-7Setting a magic cookie for an audio file"></a><p class="codesample"><strong>Listing 2-7&nbsp;&nbsp;</strong>Setting a magic cookie for an audio file</p><div class="codesample"><table><tr><td scope="row"><pre>OSStatus SetMagicCookieForFile (<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueRef inQueue,                                      // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioFileID   inFile                                        // 2<span></span></pre></td></tr><tr><td scope="row"><pre>) {<span></span></pre></td></tr><tr><td scope="row"><pre>    OSStatus result = noErr;                                    // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    UInt32 cookieSize;                                          // 4<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    if (<span></span></pre></td></tr><tr><td scope="row"><pre>            AudioQueueGetPropertySize (                         // 5<span></span></pre></td></tr><tr><td scope="row"><pre>                inQueue,<span></span></pre></td></tr><tr><td scope="row"><pre>                kAudioQueueProperty_MagicCookie,<span></span></pre></td></tr><tr><td scope="row"><pre>                &amp;cookieSize<span></span></pre></td></tr><tr><td scope="row"><pre>            ) == noErr<span></span></pre></td></tr><tr><td scope="row"><pre>    ) {<span></span></pre></td></tr><tr><td scope="row"><pre>        char* magicCookie =<span></span></pre></td></tr><tr><td scope="row"><pre>            (char *) malloc (cookieSize);                       // 6<span></span></pre></td></tr><tr><td scope="row"><pre>        if (<span></span></pre></td></tr><tr><td scope="row"><pre>                AudioQueueGetProperty (                         // 7<span></span></pre></td></tr><tr><td scope="row"><pre>                    inQueue,<span></span></pre></td></tr><tr><td scope="row"><pre>                    kAudioQueueProperty_MagicCookie,<span></span></pre></td></tr><tr><td scope="row"><pre>                    magicCookie,<span></span></pre></td></tr><tr><td scope="row"><pre>                    &amp;cookieSize<span></span></pre></td></tr><tr><td scope="row"><pre>                ) == noErr<span></span></pre></td></tr><tr><td scope="row"><pre>        )<span></span></pre></td></tr><tr><td scope="row"><pre>            result =    AudioFileSetProperty (                  // 8<span></span></pre></td></tr><tr><td scope="row"><pre>                            inFile,<span></span></pre></td></tr><tr><td scope="row"><pre>                            kAudioFilePropertyMagicCookieData,<span></span></pre></td></tr><tr><td scope="row"><pre>                            cookieSize,<span></span></pre></td></tr><tr><td scope="row"><pre>                            magicCookie<span></span></pre></td></tr><tr><td scope="row"><pre>                        );<span></span></pre></td></tr><tr><td scope="row"><pre>        free (magicCookie);                                     // 9<span></span></pre></td></tr><tr><td scope="row"><pre>    }<span></span></pre></td></tr><tr><td scope="row"><pre>    return result;                                              // 10<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The audio queue you’re using for recording.</p></li><li class="li"><p>The audio file you’re recording into.</p></li><li class="li"><p>A result variable that indicates the success or failure of this function.</p></li><li class="li"><p>A variable to hold the magic cookie data size.</p></li><li class="li"><p>Gets the data size of the magic cookie from the audio queue and stores it in the <code>cookieSize</code> variable.</p></li><li class="li"><p>Allocates an array of bytes to hold the magic cookie information.</p></li><li class="li"><p>Gets the magic cookie by querying the audio queue’s <code>kAudioQueueProperty_MagicCookie</code> property.</p></li><li class="li"><p>Sets the magic cookie for the audio file you’re recording into. The <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileSetProperty" target="_top">AudioFileSetProperty</a></code> function is declared in the <code>AudioFile.h</code> header file.</p></li><li class="li"><p>Frees the memory for the temporary cookie variable.</p></li><li class="li"><p>Returns the success or failure of this function.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW4" title="Set Up an Audio Format for Recording"></a><h2>Set Up an Audio Format for Recording</h2><p>This section describes how you set up an audio data format for the audio queue. The audio queue uses this format for recording to a file.</p><p>To set up an audio data format, you specify:</p><ul class="ul"><li class="li"><p>Audio data format type (such as linear PCM, AAC, etc.)</p></li><li class="li"><p>Sample rate (such as 44.1 kHz)</p></li><li class="li"><p>Number of audio channels (such as 2, for stereo)</p></li><li class="li"><p>Bit depth (such as 16 bits)</p></li><li class="li"><p>Frames per packet (linear PCM, for example, uses one frame per packet)</p></li><li class="li"><p>Audio file type (such as CAF, AIFF, etc.)</p></li><li class="li"><p>Details of the audio data format required for the file type</p></li></ul><p><span class="content_text">Listing 2-8</span> illustrates setting up an audio format for recording, using a fixed choice for each attribute. In production code, you’d typically allow the user to specify some or all aspects of the audio format. With either approach, the goal is to fill the <code>mDataFormat</code> field of the <code>AQRecorderState</code> custom structure, described in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW15">“Define a Custom Structure to Manage State.”</a></span></p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW17" title="Listing 2-8Specifying an audio queue&acirc;&#128;&#153;s audio data format "></a><p class="codesample"><strong>Listing 2-8&nbsp;&nbsp;</strong>Specifying an audio queue’s audio data format </p><div class="codesample"><table><tr><td scope="row"><pre>AQRecorderState aqData;                                      // 1<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mFormatID = kAudioFormatLinearPCM;        // 2<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mSampleRate = 44100.0;                    // 3<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mChannelsPerFrame = 2;                    // 4<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mBitsPerChannel = 16;                     // 5<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mBytesPerPacket =                         // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mDataFormat.mBytesPerFrame =<span></span></pre></td></tr><tr><td scope="row"><pre>        aqData.mDataFormat.mChannelsPerFrame * sizeof (SInt16);<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mFramesPerPacket = 1;                     // 7<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AudioFileTypeID fileType = kAudioFileAIFFType;               // 8<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mDataFormat.mFormatFlags =                            // 9<span></span></pre></td></tr><tr><td scope="row"><pre>    kLinearPCMFormatFlagIsBigEndian<span></span></pre></td></tr><tr><td scope="row"><pre>    | kLinearPCMFormatFlagIsSignedInteger<span></span></pre></td></tr><tr><td scope="row"><pre>    | kLinearPCMFormatFlagIsPacked;<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>Creates an instance of the <code>AQRecorderState</code> custom structure. The structure’s <code>mDataFormat</code> field contains an <code>AudioStreamBasicDescription</code> structure. The values set in the <code>mDataFormat</code> field provide an initial definition of the audio format for the audio queue—which is also the audio format for the file you record into. In <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW9">Listing 2-10</a></span>, you obtain a more complete specification of the audio format, which Core Audio provides to you based on the format type and file type.</p></li><li class="li"><p>Defines the audio data format type as linear PCM. See <em><a href="../../../Reference/CoreAudioDataTypesRef/index.html#//apple_ref/doc/uid/TP40004488" target="_top">Core Audio Data Types Reference</a></em> for a complete listing of the available data formats.</p></li><li class="li"><p>Defines the sample rate as 44.1 kHz.</p></li><li class="li"><p>Defines the number of channels as 2.</p></li><li class="li"><p>Defines the bit depth per channel as 16.</p></li><li class="li"><p>Defines the number of bytes per packet, and the number of bytes per frame, to 4 (that is, 2 channels times 2 bytes per sample).</p></li><li class="li"><p>Defines the number of frames per packet as 1.</p></li><li class="li"><p>Defines the file type as AIFF. See the audio file types enumeration in the <code>AudioFile.h</code> header file for a complete listing of the available file types. You can specify any file type for which there is an installed codec, as described in <span class="content_text"><a href="../AboutAudioQueues/AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW14">“Using Codecs and Audio Data Formats.”</a></span></p></li><li class="li"><p>Sets the format flags needed for the specified file type.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW2" title="Create a Recording Audio Queue"></a><h2>Create a Recording Audio Queue</h2><p>Now, with the recording callback and audio data format set up, you create and configure an audio queue for recording.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW25" title="Creating a Recording Audio Queue"></a><h3>Creating a Recording Audio Queue</h3><p><span class="content_text">Listing 2-9</span> illustrates how to create a recording audio queue. Notice that the <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueNewInput" target="_top">AudioQueueNewInput</a></code> function uses the callback, the custom structure, and the audio data format that were configured in previous steps.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW18" title="Listing 2-9Creating a recording audio queue"></a><p class="codesample"><strong>Listing 2-9&nbsp;&nbsp;</strong>Creating a recording audio queue</p><div class="codesample"><table><tr><td scope="row"><pre>AudioQueueNewInput (                              // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData.mDataFormat,                          // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    HandleInputBuffer,                            // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData,                                      // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    NULL,                                         // 5<span></span></pre></td></tr><tr><td scope="row"><pre>    kCFRunLoopCommonModes,                        // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    0,                                            // 7<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData.mQueue                                // 8<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueNewInput" target="_top">AudioQueueNewInput</a></code> function creates a new recording audio queue.</p></li><li class="li"><p>The audio data format to use for the recording. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">“Set Up an Audio Format for Recording.”</a></span></p></li><li class="li"><p>The callback function to use with the recording audio queue. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW24">“Write a Recording Audio Queue Callback.”</a></span></p></li><li class="li"><p>The custom data structure for the recording audio queue. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW15">“Define a Custom Structure to Manage State.”</a></span></p></li><li class="li"><p>The run loop on which the callback will be invoked. Use <code>NULL</code> to specify default behavior, in which the callback will be invoked on a thread internal to the audio queue. This is typical use—it allows the audio queue to record while your application’s user interface thread waits for user input to stop the recording.</p></li><li class="li"><p>The run loop modes in which the callback can be invoked. Normally, use the <code>kCFRunLoopCommonModes</code> constant here.</p></li><li class="li"><p>Reserved. Must be <code>0</code>.</p></li><li class="li"><p>On output, the newly allocated recording audio queue.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW23" title="Getting the Full Audio Format from an Audio Queue"></a><h3>Getting the Full Audio Format from an Audio Queue</h3><p>When the audio queue came into existence (see <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW25">“Creating a Recording Audio Queue”</a></span>), it may have filled out the <code>AudioStreamBasicDescription</code> structure more completely than you have, particularly for compressed formats. To obtain the complete format description, call the <code>AudioQueueGetProperty</code> function as shown in <span class="content_text">Listing 2-10</span>. You use the complete audio format when you create an audio file to record into (see <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW26">“Create an Audio File”</a></span>).</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW9" title="Listing 2-10Getting the audio format from an audio queue"></a><p class="codesample"><strong>Listing 2-10&nbsp;&nbsp;</strong>Getting the audio format from an audio queue</p><div class="codesample"><table><tr><td scope="row"><pre>UInt32 dataFormatSize = sizeof (aqData.mDataFormat);       // 1<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AudioQueueGetProperty (                                    // 2<span></span></pre></td></tr><tr><td scope="row"><pre>  aqData.mQueue,                                           // 3<span></span></pre></td></tr><tr><td scope="row"><pre>  kAudioConverterCurrentOutputStreamDescription,           // 4<span></span></pre></td></tr><tr><td scope="row"><pre>  &amp;aqData.mDataFormat,                                     // 5<span></span></pre></td></tr><tr><td scope="row"><pre>  &amp;dataFormatSize                                          // 6<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>Gets an expected property value size to use when querying the audio queue about its audio data format.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueGetProperty" target="_top">AudioQueueGetProperty</a></code> function obtains the value for a specified property in an audio queue.</p></li><li class="li"><p>The audio queue to obtain the audio data format from.</p></li><li class="li"><p>The property ID for obtaining the value of the audio queue’s data format.</p></li><li class="li"><p>On output, the full audio data format, in the form of an <code>AudioStreamBasicDescription</code> structure, obtained from the audio queue.</p></li><li class="li"><p>On input, the expected size of the <code>AudioStreamBasicDescription</code> structure. On output, the actual size. Your recording application does not need to make use of this value.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-SW26" title="Create an Audio File"></a><h2>Create an Audio File</h2><p>With an audio queue created and configured, you create the audio file that you’ll record audio data into, as shown in <span class="content_text">Listing 2-11</span>. The audio file uses the data format and file format specifications previously stored in the audio queue’s custom structure.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW19" title="Listing 2-11Creating an audio file for recording"></a><p class="codesample"><strong>Listing 2-11&nbsp;&nbsp;</strong>Creating an audio file for recording</p><div class="codesample"><table><tr><td scope="row"><pre>CFURLRef audioFileURL =<span></span></pre></td></tr><tr><td scope="row"><pre>    CFURLCreateFromFileSystemRepresentation (            // 1<span></span></pre></td></tr><tr><td scope="row"><pre>        NULL,                                            // 2<span></span></pre></td></tr><tr><td scope="row"><pre>        (const UInt8 *) filePath,                        // 3<span></span></pre></td></tr><tr><td scope="row"><pre>        strlen (filePath),                               // 4<span></span></pre></td></tr><tr><td scope="row"><pre>        false                                            // 5<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AudioFileCreateWithURL (                                 // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    audioFileURL,                                        // 7<span></span></pre></td></tr><tr><td scope="row"><pre>    fileType,                                            // 8<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData.mDataFormat,                                 // 9<span></span></pre></td></tr><tr><td scope="row"><pre>    kAudioFileFlags_EraseFile,                           // 10<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData.mAudioFile                                   // 11<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><a href="../../../../CoreFoundation/Reference/CFURLRef/Reference/reference.html#//apple_ref/doc/c_ref/CFURLCreateFromFileSystemRepresentation" target="_top">CFURLCreateFromFileSystemRepresentation</a></code> function, declared in the <code>CFURL.h</code> header file, creates a CFURL object representing a file to record into.</p></li><li class="li"><p>Use <code>NULL</code> (or <code>kCFAllocatorDefault</code>) to use the current default memory allocator.</p></li><li class="li"><p>The file-system path you want to convert to a CFURL object. In production code, you would typically obtain a value for <code>filePath</code> from the user.</p></li><li class="li"><p>The number of bytes in the file-system path.</p></li><li class="li"><p>A value of <code>false</code> indicates that <code>filePath</code> represents a file, not a directory.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileCreateWithURL" target="_top">AudioFileCreateWithURL</a></code> function, from the <code>AudioFile.h</code> header file, creates a new audio file or initializes an existing file.</p></li><li class="li"><p>The URL at which to create the new audio file, or to initialize in the case of an existing file. The URL was derived from the <code><a href="../../../../CoreFoundation/Reference/CFURLRef/Reference/reference.html#//apple_ref/doc/c_ref/CFURLCreateFromFileSystemRepresentation" target="_top">CFURLCreateFromFileSystemRepresentation</a></code> in step 1.</p></li><li class="li"><p>The file type for the new file. In the example code in this chapter, this was previously set to AIFF by way of the <code>kAudioFileAIFFType</code> file type constant. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">“Set Up an Audio Format for Recording.”</a></span></p></li><li class="li"><p>The data format of the audio that will be recorded into the file, specified as an <code>AudioStreamBasicDescription</code> structure. In the example code for this chapter, this was also set in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">“Set Up an Audio Format for Recording.”</a></span></p></li><li class="li"><p>Erases the file, in the case that the file already exists.</p></li><li class="li"><p>On output, an audio file object (of type <code>AudioFileID</code>) representing the audio file to record into.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_16" title="Set an Audio Queue Buffer Size"></a><h2>Set an Audio Queue Buffer Size</h2><p>Before you prepare a set of audio queue buffers that you’ll use while recording, you make use of the <code><!--a-->DeriveBufferSize<!--/a--></code> function you wrote earlier (see <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW14">“Write a Function to Derive Recording Audio Queue Buffer Size”</a></span>). You assign this size to the recording audio queue you are using. <span class="content_text">Listing 2-12</span> illustrates this:</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW27" title="Listing 2-12Setting an audio queue buffer size"></a><p class="codesample"><strong>Listing 2-12&nbsp;&nbsp;</strong>Setting an audio queue buffer size</p><div class="codesample"><table><tr><td scope="row"><pre>DeriveBufferSize (                               // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mQueue,                               // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mDataFormat,                          // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    0.5,                                         // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    &amp;aqData.bufferByteSize,                      // 5<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><!--a-->DeriveBufferSize<!--/a--></code> function, described in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW14">“Write a Function to Derive Recording Audio Queue Buffer Size,”</a></span> sets an appropriate audio queue buffer size.</p></li><li class="li"><p>The audio queue that you’re setting buffer size for.</p></li><li class="li"><p>The audio data format for the file you are recording. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW4">“Set Up an Audio Format for Recording.”</a></span></p></li><li class="li"><p>The number of seconds of audio that each audio queue buffer should hold. One half second, as set here, is typically a good choice.</p></li><li class="li"><p>On output, the size for each audio queue buffer, in bytes. This value is placed in the custom structure for the audio queue.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_17" title="Prepare a Set of Audio Queue Buffers"></a><h2>Prepare a Set of Audio Queue Buffers</h2><p>You now ask the audio queue that you’ve created (in <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW2">“Create a Recording Audio Queue”</a></span>) to prepare a set of audio queue buffers. <span class="content_text">Listing 2-13</span> demonstrates how to do this.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW20" title="Listing 2-13Preparing a set of audio queue buffers"></a><p class="codesample"><strong>Listing 2-13&nbsp;&nbsp;</strong>Preparing a set of audio queue buffers</p><div class="codesample"><table><tr><td scope="row"><pre>for (int i = 0; i &lt; kNumberBuffers; ++i) {           // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueAllocateBuffer (                       // 2<span></span></pre></td></tr><tr><td scope="row"><pre>        aqData.mQueue,                               // 3<span></span></pre></td></tr><tr><td scope="row"><pre>        bufferByteSize,                              // 4<span></span></pre></td></tr><tr><td scope="row"><pre>        &amp;aqData.mBuffers[i]                          // 5<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>    AudioQueueEnqueueBuffer (                        // 6<span></span></pre></td></tr><tr><td scope="row"><pre>        aqData.mQueue,                               // 7<span></span></pre></td></tr><tr><td scope="row"><pre>        aqData.mBuffers[i],                          // 8<span></span></pre></td></tr><tr><td scope="row"><pre>        0,                                           // 9<span></span></pre></td></tr><tr><td scope="row"><pre>        NULL                                         // 10<span></span></pre></td></tr><tr><td scope="row"><pre>    );<span></span></pre></td></tr><tr><td scope="row"><pre>}<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>Iterates to allocate and enqueue each audio queue buffer.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueAllocateBuffer" target="_top">AudioQueueAllocateBuffer</a></code> function asks an audio queue to allocate an audio queue buffer.</p></li><li class="li"><p>The audio queue that performs the allocation and that will own the buffer.</p></li><li class="li"><p>The size, in bytes, for the new audio queue buffer being allocated. See <span class="content_text"><a href="RecordingAudio.html#//apple_ref/doc/uid/TP40005343-CH4-SW14">“Write a Function to Derive Recording Audio Queue Buffer Size.”</a></span></p></li><li class="li"><p>On output, the newly allocated audio queue buffer. The pointer to the buffer is placed in the custom structure you’re using with the audio queue.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueEnqueueBuffer" target="_top">AudioQueueEnqueueBuffer</a></code> function adds an audio queue buffer to the end of a buffer queue.</p></li><li class="li"><p>The audio queue whose buffer queue you are adding the buffer to.</p></li><li class="li"><p>The audio queue buffer you are enqueuing.</p></li><li class="li"><p>This parameter is unused when enqueuing a buffer for recording.</p></li><li class="li"><p>This parameter is unused when enqueuing a buffer for recording.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_18" title="Record Audio"></a><h2>Record Audio</h2><p>All of the preceding code has led up to the very simple process of recording, as shown in <span class="content_text">Listing 2-14</span>.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW21" title="Listing 2-14Recording audio"></a><p class="codesample"><strong>Listing 2-14&nbsp;&nbsp;</strong>Recording audio</p><div class="codesample"><table><tr><td scope="row"><pre>aqData.mCurrentPacket = 0;                           // 1<span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mIsRunning = true;                            // 2<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AudioQueueStart (                                    // 3<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mQueue,                                   // 4<span></span></pre></td></tr><tr><td scope="row"><pre>    NULL                                             // 5<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr><tr><td scope="row"><pre>// Wait, on user interface thread, until user stops the recording<span></span></pre></td></tr><tr><td scope="row"><pre>AudioQueueStop (                                     // 6<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mQueue,                                   // 7<span></span></pre></td></tr><tr><td scope="row"><pre>    true                                             // 8<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>aqData.mIsRunning = false;                           // 9<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>Initializes the packet index to <code>0</code> to begin recording at the start of the audio file.</p></li><li class="li"><p>Sets a flag in the custom structure to indicate that the audio queue is running. This flag is used by the recording audio queue callback.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStart" target="_top">AudioQueueStart</a></code> function starts the audio queue, on its own thread.</p></li><li class="li"><p>The audio queue to start.</p></li><li class="li"><p>Uses <code>NULL</code> to indicate that the audio queue should start recording immediately.</p></li><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueStop" target="_top">AudioQueueStop</a></code> function stops and resets the recording audio queue.</p></li><li class="li"><p>The audio queue to stop.</p></li><li class="li"><p>Use <code>true</code> to use synchronous stopping. See <span class="content_text"><a href="../AboutAudioQueues/AboutAudioQueues.html#//apple_ref/doc/uid/TP40005343-CH5-SW17">“Audio Queue Control and State”</a></span> for an explanation of synchronous and asynchronous stopping.</p></li><li class="li"><p>Sets a flag in the custom structure to indicate that the audio queue is not running.</p></li></ol><a name="//apple_ref/doc/uid/TP40005343-CH4-DontLinkElementID_19" title="Clean Up After Recording"></a><h2>Clean Up After Recording</h2><p>When you’re finished with recording, dispose of the audio queue and close the audio file. <span class="content_text">Listing 2-15</span> illustrates these steps.</p><a name="//apple_ref/doc/uid/TP40005343-CH4-SW22" title="Listing 2-15Cleaning up after recording"></a><p class="codesample"><strong>Listing 2-15&nbsp;&nbsp;</strong>Cleaning up after recording</p><div class="codesample"><table><tr><td scope="row"><pre>AudioQueueDispose (                                 // 1<span></span></pre></td></tr><tr><td scope="row"><pre>    aqData.mQueue,                                  // 2<span></span></pre></td></tr><tr><td scope="row"><pre>    true                                            // 3<span></span></pre></td></tr><tr><td scope="row"><pre>);<span></span></pre></td></tr><tr><td scope="row"><pre> <span></span></pre></td></tr><tr><td scope="row"><pre>AudioFileClose (aqData.mAudioFile);                 // 4<span></span></pre></td></tr></table></div>	<p>Here’s how this code works:</p><ol class="ol"><li class="li"><p>The <code><a href="../../../Reference/AudioQueueReference/Reference/reference.html#//apple_ref/doc/c_ref/AudioQueueDispose" target="_top">AudioQueueDispose</a></code> function disposes of the audio queue and all of its resources, including its buffers.</p></li><li class="li"><p>The audio queue you want to dispose of.</p></li><li class="li"><p>Use <code>true</code> to dispose of the audio queue synchronously (that is, immediately).</p></li><li class="li"><p>Closes the audio file that was used for recording. The <code><a href="../../../Reference/AudioFileConvertRef/Reference/reference.html#//apple_ref/doc/c_ref/AudioFileClose" target="_top">AudioFileClose</a></code> function is declared in the <code>AudioFile.h</code> header file.</p></li></ol><!-- <Section XRefSourceID="SW2"><Name>Obtaining Property Data from a Recording Device</Name><Para>If you want to obtain property data from a recording device, you get the default recording device for your audio and determine its format, including its sample rate and its <codeVoice xml:space="preserve">AudioStreamBasicDescription</codeVoice> structure.</Para><Para>You get the device identification number of the default recording device by calling the <codeVoice xml:space="preserve">AudioObjectGetPropertyData</codeVoice> function (which is in <codeVoice xml:space="preserve">AudioServices.h</codeVoice> in the Audio Toolbox framework), as shown here:s</Para><CodeListing><CodeLines-Full><CodeLine xml:space="preserve">AudioObjectGetPropertyData (</CodeLine><CodeLine xml:space="preserve">    kAudioObjectSystemObject,</CodeLine><CodeLine xml:space="preserve">    &amp;addr,</CodeLine><CodeLine xml:space="preserve">    0, </CodeLine><CodeLine xml:space="preserve">    NULL</CodeLine><CodeLine xml:space="preserve">    &amp;size,</CodeLine><CodeLine xml:space="preserve">    &amp;deviceID)</CodeLine><CodeLine xml:space="preserve">;</CodeLine></CodeLines-Full></CodeListing><Para>Alternatively, using <codeVoice xml:space="preserve">AudioHardwareServiceGetPropertyData:</codeVoice></Para><CodeListing><CodeLines-Full><CodeLine xml:space="preserve">AudioHardwareServiceGetPropertyData (</CodeLine><CodeLine xml:space="preserve">   kAudioObjectSystemObject,</CodeLine><CodeLine xml:space="preserve">   &amp;addr, </CodeLine><CodeLine xml:space="preserve">   0, </CodeLine><CodeLine xml:space="preserve">   NULL, </CodeLine><CodeLine xml:space="preserve">   &amp;size,</CodeLine><CodeLine xml:space="preserve">   &amp;deviceID</CodeLine><CodeLine xml:space="preserve">);</CodeLine></CodeLines-Full></CodeListing><Para> You can also use the <codeVoice xml:space="preserve">AudioHardwareServiceGetPropertyData</codeVoice> function (which is in <codeVoice xml:space="preserve">AudioHardware.h</codeVoice> in the Core Audio framework), as shown here:</Para><Para>In both functions, a query is made to an audio object to obtain the device identification number and it is placed in the specified buffer. The functions:</Para><List-Bullet><Item><Para>Query the <codeVoice xml:space="preserve">kAudioObjectSystemObject</codeVoice> property.</Para></Item><Item><Para>Provide a pointer to the address indicating the <codeVoice xml:space="preserve">kAudioObjectSystemObject</codeVoice> property.</Para></Item><Item><Para>Pass <codeVoice xml:space="preserve">0</codeVoice> to indicate this property requires no qualification regarding data size.</Para></Item><Item><Para>Pass <codeVoice xml:space="preserve">NULL</codeVoice> to indicate this property requires no qualification regarding data related to the property.</Para></Item><Item><Para>Provide a pointer to a <codeVoice xml:space="preserve">UInt32</codeVoice> value, which on entry indicates the size of the buffer pointed to by <codeVoice xml:space="preserve">deviceID</codeVoice> and on exit indicates how much of the buffer was used.</Para></Item><Item><Para>Provide a pointer where the audio object is to place the data for the <codeVoice xml:space="preserve">kAudioObjectSystemObject</codeVoice> property.</Para></Item></List-Bullet><Section><Name>Getting the Sample Rate for an Audio Device</Name><Para>Once you have obtained the device ID, you use the <codeVoice xml:space="preserve">AudioObjectGetPropertyData</codeVoice> function to get the sample rate of the audio device you are recording from, as shown in <xName DestinationChapterID="CH4" Id="SW3" targetElementType="Section">“Stopping Audio”</xName>. (As with obtaining property data from a recording device, you could also use the <codeVoice xml:space="preserve">AudioServiceGetPropertyData</codeVoice> function to get this information.)</Para><CodeListing><Name>Getting the sample rate of an audio device</Name><CodeLines-Full><CodeLine xml:space="preserve">addr.mSelector = kAudioDevicePropertyNominalSampleRate;</CodeLine><CodeLine xml:space="preserve">addr.mScope = kAudioObjectPropertyScopeGlobal;</CodeLine><CodeLine xml:space="preserve">addr.mElement = 0;</CodeLine><CodeLine xml:space="preserve">size = sizeof(Float64);</CodeLine><CodeLine xml:space="preserve"></CodeLine><CodeLine xml:space="preserve">AudioObjectGetPropertyData (</CodeLine><CodeLine xml:space="preserve">    deviceID,</CodeLine><CodeLine xml:space="preserve">    &amp;addr, </CodeLine><CodeLine xml:space="preserve">    0, </CodeLine><CodeLine xml:space="preserve">    NULL,</CodeLine><CodeLine xml:space="preserve">    &amp;size,</CodeLine><CodeLine xml:space="preserve">    &amp;rec.mRecordFormat.mSampleRate</CodeLine><CodeLine xml:space="preserve">);</CodeLine></CodeLines-Full></CodeListing><Para>The default audio device is queried to:</Para><List-Bullet><Item><Para>Specify the default recording device as the audio object.</Para></Item><Item><Para>Provide the address at which the default recording device is being queried.</Para></Item><Item><Para>Pass <codeVoice xml:space="preserve">0</codeVoice> to indicate this property requires no qualification regarding data size.</Para></Item><Item><Para>Pass <codeVoice xml:space="preserve">NULL</codeVoice> to indicate this property requires no qualification regarding data related to the property.</Para></Item><Item><Para>Provide a pointer to a <codeVoice xml:space="preserve">UInt32</codeVoice> value, which on entry indicates the size of the buffer pointed to by the <codeVoice xml:space="preserve">deviceID</codeVoice> parameter and on exit indicates how much of the buffer was used.</Para></Item><Item><Para>Provide a pointer where the audio object is to place the data for the <codeVoice xml:space="preserve">rec.mRecordFormat.mSampleRate</codeVoice> property.</Para></Item></List-Bullet></Section></Section> -->

        <br /><br /> 
        
        <div class="mini_nav_text" align="left">
        <span class="navButtons">
        <a href="../AboutAudioQueues/AboutAudioQueues.html">&lt; Previous Page</a><span style="margin-left: 8px"><a href="../AQPlayback/PlayingAudio.html">Next Page &gt;</a></span>
        </span>
        <span id="showHideTOCLowerSpan">
        <a href="#" onclick="showHideTOC();"><img src="../../../../Resources/Images/show_toc_icon.gif" width="15" height="14" border="0" style="margin-bottom: -2px;" alt="" /></a> <a href="#" onclick="showHideTOC();">Hide TOC</a>
        </span>
        </div>

        <br/><hr /><div align="center"><p class="content_text" lang="en" dir="ltr"> <!--#if expr="0=1" -->&#x00a9; 2007 Apple Inc. All Rights Reserved. &#40;<!--#endif -->Last updated: 2007-10-31<!--#if expr="0=1" -->&#041;<!--#endif --></p></div>

        
        <div class="hideOnPrint hideInXcode">
        <!-- start of footer -->
        	<table width="100%" border="0" cellpadding="0" cellspacing="0">
		<tr>
			<td><div style="width: 100%; height: 1px; background-color: #919699; margin-top: 5px; margin-bottom: 15px"></div></td>
		</tr>
		<tr>
			<td align="center"><br/>
				<table border="0" cellpadding="0" cellspacing="0" class="graybox">
					<tr>
						<th>Did this document help you?</th>
					</tr>
					<tr>
						<td>
						    <div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=1&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AQRecord/RecordingAudio.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>Yes</a>:  Tell us what works for you.</div>
							<div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=2&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AQRecord/RecordingAudio.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>It&#8217;s good, but:</a> Report typos, inaccuracies, and so forth.</div>
							<div><a href="http://developer.apple.com/feedback/?v=3&url=/documentation/MusicAudio/Conceptual/AudioQueueProgrammingGuide/AQRecord/RecordingAudio.html%3Fid%3DTP40005343-1.0&media=dvd" target=_new>It wasn&#8217;t helpful</a>: Tell us what would have helped.</div>
						</td>
					</tr>
				</table>
			</td>
		</tr>
	</table>

        <!--#include virtual="/includes/framesetfooter" -->
        <!-- end of footer -->
        </div>
    </div>
</body>
</html>