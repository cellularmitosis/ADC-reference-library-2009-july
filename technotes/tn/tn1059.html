<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"			"http://www.w3.org/TR/REC-html40/loose.dtd"><HTML><!-- Template 03-24-01 --><HEAD><LINK REL="stylesheet" HREF="../../adcstyle.css" TYPE="text/css"><LINK REL="stylesheet" HREF="../../style.css" TYPE="text/css"><title>Technical Note TN1059: On Improving Open Transport Network Server Performance</title>    <meta name="keywords" content="Mac OS 8 Open Transport improving network server performance packets">    <meta name="Description" content="Technical Note TN1059: This Technical Note is intended forMacintosh developers writing network server applicationsthat use the Open Transport API, and discusses some techniquesyou can employ in your network server application designto achieve higher performance. Included is a list of Interrupt-safeOpen Transport functions and a discussion of using Open Transportwith the File Manager."><meta name="categories" content="Networking"><meta name="week-posted" content="Jul 1, 1996 - Jul 5, 1996"><LINK REL="stylesheet" HREF="../../css/adcstyle.css" TYPE="text/css"><script language="JavaScript" type="text/javascript" src="../../js/adc.js"></script></HEAD><BODY BGCOLOR="#FFFFFF"><a name="//apple_ref/doc/uid/DTS10002900" title="On Improving Open Transport Network Server Performance"></a><A NAME="top"></A><!-- begin_header_information --><!--#include virtual="/adcnavbar" --><p><a href="http://developer.apple.com/">ADC Home</a> &gt; <a href="../../referencelibrary/index.html">Reference Library</a> &gt; <a href="../../technicalnotes/index.html">Technical Notes</a> &gt; <a href="../../technicalnotes/LegacyTechnologies/index.html">Legacy Documents</a> &gt; <a href="../../technicalnotes/LegacyTechnologies/idxNetworking-date.html">Networking</a> &gt; </p><div style="width:100%; position:fixed;"><div align="center" id="watermark" style="position: relative; margin-left:auto; margin-right:auto; z-index:20; width:500px;"><div class="legacybox"><h1>Legacy Document<span class=closebutton><a href="javascript:closeWatermark()"><img src="../../images/closebutton.png" width="14" height="14" border="0"  alt="close button"></a></span></h1>

<p><strong>Important: </strong>This document is part of the Legacy section of the ADC Reference Library. This information should not be used for new development.</p>

<div class="reflibtopic">
	<p>Current information on this Reference Library topic can be found here:</p>
	<ul>
				<li><a href="http://developer.apple.com/referencelibrary/Networking/index.html" target="_blank">Reference Library > Networking</a></li>
	</ul>
</div>




</div></div></div><!-- end_header_information --><!-- bottom_of_header_marker_comment --><!-- top_of_titles_marker_comment --><CENTER><table width="600" cellpadding="0" cellspacing="0" border="0">
<tr><td align="left" scope="row">
<h1>
<div id="pagehead">Technical Note TN1059</div>
<div id="pageheadsub">On Improving Open Transport Network Server Performance</div>
</h1>
</td></tr></table></CENTER><!-- bottom_of_titles_marker_comment --><CENTER><TABLE BORDER=0 CELLSPACING=1 WIDTH=600><TR><td align="left"> <!-- begin_header_box --> <table width="600" cellpadding="0" cellspacing="0" border="0">	<tr>		<td width=300 valign="top" align=left scope="row">			<table border="0" width="300" cellpadding="0" cellspacing="0">			<tr>                        <td width=300 align=left> <img src="images/tnmenutop.gif" alt="" align="bottom" width=300 height=7></td>				</tr>				<tr bgcolor="#e6e6e6">					<td background="images/tnmenubody.gif" width=300 align=left>						<span id="menutitle">							CONTENTS                             <br>                            <br>						</span>					</td>				</tr>				<tr bgcolor="#e6e6e6">					<td background="images/tnmenubody.gif" width=300 align=left><!-- begin_toc --><p id="menutext"><A HREF = "#RTFToC1">About Open Transport on Mac OS</a><br><br><A HREF = "#RTFToC2">Getting the Most Out of Open Transport By Using Notifiers</a><br><br><A HREF = "#RTFToC3">Using Open Transport with the File Manager</a><br><br><A HREF = "#RTFToC4">Streamlining Endpoint Creation</a><br><br><A HREF = "#RTFToC5">Increasing Throughput</a><br><br><A HREF = "#RTFToC6">Other Tips to Improve Performance</a><br><br><A HREF = "#Summary">Summary</a><br><br><A HREF="#References">References</A><BR><BR><A HREF="#Downloads">Downloadables</A></p>			<!-- end_toc --> 								</td>				</tr>				<tr>					<td width=300 align=left scope="row">						<img src="images/tnmenubottom.gif" alt="" width=300 height=16>					</td>				</tr>			</table>		</td>		<td width=300 valign="top" align=left>			<!-- begin_intro_text --><P id = "introtext">As higher network datalink speeds become more commonplace, Mac&nbsp;OS serverperformance has come under closer scrutiny. Developers who write network serverapplications on the Mac continue to be concerned about performance issues. Inmany cases, server throughput and connection latency problems may stem frompoor application design rather than any deficiencies in Open Transport or theMac OS.</p><P id = "introtext">This Technote is intended for Macintosh developers writing network serverapplications that use the Open Transport API, and discusses some techniques youcan employ in your network server application design to achieve higherperformance.</p><!-- end_intro_text --><!-- begin_date --><h3>&nbsp;Updated: [July 1 1996]</h3><!-- end_date -->                </TD>             </TR>          </TABLE>          <!-- end_header_box --> <BR><BR><hr width=500 align=center>          <BR><BR> <!-- begin_content --><a name = "RTFToC1"></a><H2>About Open Transport on Mac OS</H2><P>The Mac OS Open Transport API is based on the industry standard X/OpenTransport Interface (XTI) specification. Since XTI originated in the UNIXworld, it was slightly altered to operate in an asynchronous environment suchas the Mac&nbsp;OS .</p><P>When using XTI under UNIX, it is acceptable for a task to issue a blocking I/Orequest, causing the process to sleep until the request is completed. But sincethe current Mac OS is based on cooperative rather than preemptive multitasking,blocking I/O is unacceptable. As a consequence, applications must invoke theirnetworking and I/O functions asynchronously; otherwise, the blocking of I/Odirectly affects the user experience.</p><P>Apple's Open Transport addresses this mismatch in software architecture byextending XTI, so that an application can install a notifier to receivecompletion events.</p><P>The key to building an application that takes full advantage of Open Transporton the Macintosh, such as a high performance network server, is the proper useof use of these XTI extensions. Understanding these extensions is important toboth developers who are writing new Macintosh network server applications andthose who attempt to port existing code based on UNIX sockets.</p><P><A HREF="#top">Back to top</A></P><a name = "RTFToC2"></a><H2>Getting the Most Out of Open Transport By Using Notifiers</H2><p>The Mac OS implementation of XTI allows your application to specify a callbackroutine or notifier upon opening an endpoint. Since the notifier mechanism isthe most immediate way for an application to discover what endpoint events areoccurring, your code should attempt to respond to most actions directly in thenotifier.</p><p>To get the maximum performance out of Open Transport, you ought to takeadvantage of notifiers. The following sections explain how to work withnotifiers.</p><H3>Don't put off to event time what you can handle in your notifier</H3><p>In the Mac OS, you have three execution contexts: </p><ul><li>System Task -- WaitNextEvent</li><li>Deferred Task -- Secondary Interrupt, when the interrupt mask is zero</li><li>Primary Interrupt -- I/O completion, VBL or Time Manager tasks</li></ul><P>In general, network server code should avoid deferring incoming packetprocessing to System Task time. The reason is that calling <code>WaitNextEvent</code> canresult in an unpredictable packet processing latency. As a result, the roundtrip time from when your server receives a packet to when it responds dependson factors external to your application. This is a consequence of cooperativemultitasking used by the Mac OS. <i>What this means is that you have nocontrol of how long it takes for another task to call </i><code>WaitNextEvent</code>.</p><P>Open Transport 1.1.1 introduced the <code>SyncIdleEvents</code> feature, which wasintended to facilitate Notifier/Thread Manager interaction. What the featuredoes is call your notifier at a time when it is safe to call <code>YieldtoThread</code>.Since <code>YieldtoThread</code> will eventually cause the Thread Manager to switch to athread that calls <code>WaitNextEvent</code>, this presents the same unpredictable latency.For this reason, I would suggest not to use this strategy in a high performanceserver.</p><P>A better strategy to processing incoming packets is to receive and initiate allI/O from the notifier. As a rule, if you can start an <code>OTSnd</code> or an asynchronousFile Manager operation from a notifier, you should do it. This is the mostimportant piece of advice you can follow if you want to extract the bestperformance from Open Transport. Network applications developers, especiallythose designing HTTP servers, should heed this recommendation. Packet-responsetime is a true measure of Web server performance.</p><P>Specifically, in a Notifier you should be able to perform the followingtasks: </p><ul><li>Accept and hand off connections</li><li>Receive and process all incoming data</li><li>Start asynchronous I/O operations, e.g., File Manager</li><li>Send network data</li><li>Tear down network connections.</li></ul><H3>Some Notifier Hints and Guidelines</H3><P>Because proper use of Open Transport notifiers is the key to improved serverperformance, here are some hints and guidelines to help you use notifiers moreeffectively: </p><ul><li>Receive and process network data from the notifier. Don't defer processing toSystem Task, since this directly affects your turnaround time.</li><li>Treat the notifier code path as a critical section; assume you are lockingthe operating system from other tasks: keep it short and simple. If you mustperform a lengthy operation, consider using a Deferred Task.</li><li>Open Transport will never run a notifier during a Primary Interrupt, only atSystem Task or Deferred Task time. A Deferred Task, also known as SecondaryInterrupt, occurs when the interrupt mask is zero, i.e., on the way out of aPrimary Interrupt. </li><li>It is also possible for Open Transport to run a notifier during the executionof or returning from an OT routine. Therefore, you should never call OT atPrimary Interrupt time, except to schedule a Deferred Task.</li> <li>You should never make a synchronous OT call from inside a notifier. Doingthis will cause Open Transport to return <code>kOTStateChangeErr</code> in order to preventyou from deadlocking.</li><li>You can use completion events to gate endpoint action, i.e., you can use<code>T_OPENCOMPLETE</code> to initiate an <code>OTBind</code> or <code>T_DISCONNECTCOMPLETE</code> to gate an<code>OTUnBind</code>. This method will prevent you from receiving a <code>kOTStateChangeErr</code> forcalling a function before an endpoint is ready.</li><li>The normal XTI events (<code>T_DATA</code>, <code>T_LISTEN</code> ...) and the completion events(<code>T_OPENCOMPLETE</code>, <code>T_BINDCOMPLETE</code> ...) will not reenter the notifier. The eventsthat do are <code>T_MEMORYRELEASED</code> and some of the high priority notifications, suchas kOTProviderWillClose. For example: <ol><li>Your notifier receives a <code>T_GODATA</code>.</li><li>The notifier responds by calling <code>OTSnd</code>.</li><li>Notifier reenters with <code>T_MEMORYRELEASED</code>.</li><li><code>OTSnd</code> returns.</li></ol></li><li>Starting with Open Transport 1.1.1, you can use the <code>OTEnterNotifier</code> and<code>OTLeaveNotifier</code> functions to prevent your notifier from being entered during acritical section of code.</li><li>For a list of OT functions and in what context you can call them, refer toAppendix F in the <i>Open Transport Client Developer Note</i>.</li></ul><H3>Interrupt-Safe Functions</H3><P>One of the major reasons that developers have shied away from processingpackets in a notifier is you can't call the Mac Toolbox functions that movememory at interrupt time. A number of fast, interrupt-safe functions, however,are available from Open Transport. These functions are the same for both Mac OS7 and <br>Mac OS 8.</p><P>Many developers may overlook the functions available in the OT library. The<i>Open Transport Client Developer Note</i> and the &lt;Opentransport.h&gt;include file ought to provide you with the information you need.</p><P>Some interrupt-safe functions available under Open Transport are explained inthe next section.</p><B>Memory Management</B><P><code>OTAllocMem/OTFreeMem</code> can be safely called from a notifier. Keep in mind thatthe memory pool used by <code>OTAllocMem</code> is allocated from the application memorypool, which, due to the Memory Manager's constraints, can only be filled attask time.</p><P>Therefore, if you allocate memory from the Open&nbsp;Transport memory pool froman interrupt or deferred task, you should be prepared to handle a failureresulting from an temporarily depleted memory pool, which can only bereplenished at the System Task time.</p><B>List Management</B><p>OTLIFO functions can be used to implement an interrupt-safe LIFO or FIFO list.Here's how: </p><ol><li>Create a <code>OTLIFO</code> list.</li><li>Populate it at interrupt or notifier time by using <code>OTLIFOEnqueue</code>.</li><li>Use the <code>OTLIFOStealList</code> to atomically remove the list and then call<code>OTReverseList</code> to flip it around, so that it will become a <code>FIFO</code> list.</li><li>You can then use <code>OTLIFODequeue</code> to remove individual elements from thelist.</li></ol><B>Semaphores</B><p>There are also a number of Atomic functions and macros, such asO<code>TAtomicSet/Clear/TestBit</code>, <code>OTCompareAndSwap</code>, <code>OTAtomicAdd</code>,<code>OTClearLock/OTAcquireLock</code> that can be used to administrate interrupt-safesemaphores.</p><B>TimeStamp</B><p>There are a number of <code>TimeStamp</code> functions that can be used to accumulateprofiling information -- for example, <code>OTGetTimeStamp</code>. These functions are fastand safe to call at Primary Interrupt time. You can use this time stampinformation later to identify bottlenecks or report on application performance.</p><H3>Open Transport Deferred Tasks: A Closer Look</H3><p>Open Transport Deferred Tasks provides a way to simplify working with primaryinterrupts, such as IO completions, VBL tasks, or Time Manager tasks. Rememberthat a Deferred Task, also known as Secondary Interrupt, occurs on the way outof processing a primary interrupt, after the interrupt mask has been lowered tozero. Deferred Tasks are in effect a priority above SystemTask, but still canbe interrupted by a Primary Interrupt such as packet reception.</p><P><code>OTCreateDeferredTask</code> can be used to setup a block of code that can be scheduledfrom primary interrupts to run at next Deferred Task time. Just pass<code>OTCreateDeferredTask</code> a pointer to the function you wish to schedule and ancontextInfo argument, and it returns you a reference that can be used later toschedule the function.</p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>    dtRef = OTCreateDeferredTask(taskproc,  contextInfo);</pre>	</TD></TR></TABLE></CENTER><P>You can then use <code>OTScheduleDeferredTask</code> to schedule the function associatedwith the reference to run at the next Deferred Task time. Once scheduled, thefunction pointed to by taskproc will be called back at the appropriate time andpassed contextInfo as a parameter.</p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>    if(  OTScheduleDeferredTask(dtRef) ) ... ;</pre>	</TD></TR></TABLE></CENTER><P>The <code>OTScheduleDeferredTask</code> will return true if the function was scheduled,false if not. If the function was not scheduled, and the <code>dtCookie</code> parameter isvalid, then this indicates that the function is already scheduled to run.</p>    <BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Note:</B><BR>         Although you can call <code>OTScheduleDeferredTask</code> at any time aduring primary interrupt, you must bracket the call with a <code>OTEnterInterrupt</code> /<code>OTLeaveInterrupt</code> pair, or better yet, use <code>OTScheduleInterruptTask</code>.</P></TD></TR></TABLE></CENTER><BR><BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Warning:</B><BR>Since Open Transport does not keep track of outstandingDeferred Task requests, it is your application's responsibility before quittingto ensure that all outstanding Deferred Task requests have either fired, orhave been cancelled with the <code>OTDestroyDeferredTask</code> call.</P></TD></TR></TABLE></CENTER><BR><H3>Avoiding Synchronization Problems</H3><p>If you mix the processing of <code>OTRcv</code> in different interrupt contexts, such asnotifier and Deferred Task or SystemTask time, you should be aware that certainsynchronization problems can occur.</p><p>For example:</p><ol><li>You call <code>OTRcv</code> from your main thread.</li><li>There is no pending data, so OT returns a <code>kOTNoDataErr</code>.</li><li>Just then, an inbound data packet interrupts OT, causing it to step down todeferred task time to process the data.</li><li>OT calls your notifier with a <code>T_DATA</code> event, which you ignore.</li><li>Although the <code>OTRcv</code> in your main thread completes with a <code>kOTNoDataErr</code>, youhave no way of knowing that you got the <code>T_DATA</code> event, and you won't get anotherone until you read to <code>kOTNoDataErr</code> again.</li><li>The result: your application hangs.</li></ol><P><A HREF="#top">Back to top</A></P><a name = "RTFToC3"></a><H2>Using Open Transport with the File Manager</H2>Since the design of many network server applications requires interaction withthe File Manager, it's important to understand how to get the most out of theFile Manager.<H3>Not Blaming the File Manager for Poor Application Design</H3>Improper use of the File Manager will adversely affect network serverperformance. If the architecture of your server requires even moderate amountsof file access, you should review Technote <i>FL16 - File Manager Performanceand Caching</i>. This Note details tactics you can apply in order to get thebest performance from the File Manager. Pay close attention to the followingissues: <ul><li>Optimizing the size of your I/O requests</li><li>Aligning your I/O requests</li><li>Using the File System's Cache to your advantage </li><li>Using asynchronous read or writes that overlap with othernon-File&nbsp;Manager operations.</li></ul><H3>Caching Open Files, Not Just Data</H3><P>An excellent way to improve performance is to avoid opening frequently usedfiles every time they are accessed. You can accomplish this by maintaining themost recent or commonly used files in an open state, tracked by a list orcache, and   only closing files after the list is full or an extended period ofinactivity has elapsed.</p><p>For example, a webserver would benefit by keeping the site's main<b>index.html</b> file open because it is hit everytime a new user accesses theserver.</p><p>There are some tradeoffs, however, to keeping a large number of files open:</p> <ul><li>HFS limits you to a fixed number of open files per disk.</li><li>Too many open files may cause other applications to fail.</li><li>Open files may be tricky to share because of synchronization issues.</li></ul><H3>An Example of Processing a Packet</H3><P>So far, I've provided you with a collection of hints and guidelines. Now I wantto show you how you might use notifiers effectively to handle packet receptionand processing.</p><P>We're going to set up a example scenario of processing a packet in the contextof an HTTP server. Let's make the following assumptions: </p><ul><li>You have open and bound your session endpoint.</li><li>AckSends are enabled. </li><li>You have also created a deferred task using <code>OTCreateDeferredTask</code> to handlenetwork replies to be used later from File Manager ioCompletion proc.</li></ul><p>Here's the scenario: </p><p>A HTTP GET-method packet is sent to your port.</p><ol><li>Your notifier receives a <code>T_DATA</code> event.</li><li>Call into <code>OTRcv</code> to extract data from the stream head, copying thedata into a buffer you allocated with the <code>OTAllocMem</code> function.</li><li>Return to step 2 until the OTRcv returns a <code>kOTNoDataErr</code>.</li><li>After parsing your data, you determined that it was a GET-request and afile access is required to respond.</li><li>Your parser calls <code>OTFreeMem</code> to return the request buffer.</li><li>Your code calls <code>PBHOpenDFAsync</code> with a pointer to a ioCompletionroutine chains to the rest of the required I/O.</li><li>The notifier returns and the main thread continues.</li><li>Some time later, the main task is interrupted to process the<code>PBHOpenDFAsync</code> completion routine, which allocates a block of memory via<code>OTAllocMem</code> for the HTTP response. <code>PBReadAsync</code> is used to access the data.</li><li>The <code>PBReadAsync</code> completes and its <code>ioCompletion</code> routine runs.</li><li>Since File Manager <code>ioCompletion</code> routines can sometimes be run at primaryinterrupt time, it is not safe to directly call Open Transport here. Instead,you should queue your network reply data to your sending task and schedule itto be run with <code>OTScheduleInterruptTask</code>. Then return from the ioCompletionroutine.</li><li>The previously scheduled Deferred Task is run, which can now safely callOTSnd to transmit the HTTP GET-response.</li><li>Close the file with <code>PBCloseAsync</code>.</li><li>The <code>OTSnd</code> completes and the notifier is called with a<code>T_MEMORYRELEASED</code> event.</li><li>The Notifier calls <code>OTFreeMem</code>.</li></ol><P><A HREF="#top">Back to top</A></P><a name = "RTFToC4"></a><H2>Streamlining Endpoint Creation</H2><P>The time required to create and open an endpoint can directly impact connectionset-up time. This is of prime concern for servers, especially HTTP servers,since they must manage high connection turnover rates. Here are three tips thatwill speed up endpoint creation.</p><H3>Preallocating Endpoints</H3><P>One cost of the transport independence provided by Open Transport is that theprocess of setting up STREAMS plumbing for each endpoint can be time consuming.</p><P>Rather than incur this delay each time a connection is established, a serverdesigned to handle multiple outstanding connections can preallocate a pool ofopen, unbound endpoints into an endpoint cache. When a connection is requested,you can quickly dequeue a ready-to-use endpoint from this cache, resulting in adecreased connection turnaround delay (e.g., 10 to 30 times faster). Forexample: </p><ol><li>Open a number of endpoints with <code>OTAsyncOpenEndpoint</code>.</li><li>When the notifier receives the T_OPENCOMPLETE event, queue the returnedEndpointRef to endpoint-cache. </li><li>When your accepting notifier receives the <code>T_LISTEN</code> event, you can dequeuean endpoint from the endpoint-cache and pass it to <code>OTAccept</code>. Thus, the onlytime you have to wait for a endpoint to be created is if the queue is empty,where you can allocate a block of endpoints.</li> </ol> <H3>Recycling Endpoints</H3><P>You can use the endpoint-cache to recycle endpoints when your connection isclosed. Rather than call <code>OTCloseProvider</code> each time a connection terminates,cache the unbound endpoint. This recycles it for a later open request.</p><ol><li>On receiving the <code>T_DISCONNECT</code>, unbind the endpoint with OTUnbind.</li><li>When your session endpoint receives the <code>T_UNBINDCOMPLETE</code> event,enqueue that endpoint into your endpoint-cache.</li></ol><P>Optionally, to save memory, you can deallocate the endpoint when theendpoint-cache reaches some predetermined limit.</p><H3>Cloning Configurations</H3><p>Another tactic to consider is to create a single <code>OTConfiguration</code> with<code>OTCreateConfiguration</code>, then use <code>OTCloneConfiguration</code> to pass the<code>OTConfiguration</code> to the <code>OTOpenEndpoint</code>. You'll find that <code>OTCloneConfiguration</code> isapproximately 5 times faster than <code>OTCreateConfiguration</code>.</p><P>Don't forget to free up the initial <code>OTConfiguration</code> before you quit yourapplication.</p><P><A HREF="#top">Back to top</A></P><H2>Managing the Connection Queue</H2><P>A high-performance server must be able to handle multiple connectionssimultaneously -- and efficiently. How you manage the connection queue is a keycomponent of this. The connection queue determines the number of outstandingconnect indications or <i>calls</i> for a server's listening endpoints -- i.e.,connections that have neither been accepted via OTAccept nor rejected via<code>OTSndDisconnect</code>.</p><P>Under the XTI framework, managing the connection queue can be complicated. Thefollowing section discusses the problems that you might encounter -- as well asthe solutions.</p><H3>Handling kOTLookErr</H3><P>One consequence of setting up a connection-oriented, listening endpoint tohandle multiple outstanding calls is being able to handle the (dread) LookError, or <code>kOTLookErr</code>. The <code>kOTLookErr</code> occurs when another concurrent event hasarrived on the same endpoint, and cannot be acted on until the blocking eventis consumed.</p><B>The Problem</B><p>To help illustrate why <code>kOTLookErr</code> occurs, you may want to think of thelistening endpoint stream head as an event FIFO. When you bind the listeningendpoint, you specify the queue length of this FIFO. If you specify a queuelength of greater than one, then multiple <code>T_LISTEN</code> or <code>T_DISCONNECT</code> events willqueue up.</p><p>Certain rules apply when processing this queue. The rules which regulate yourinteraction with this queue are codified by the X/Open&nbsp;XTI specification.The following are the relevant rules you need to know in order to write yourconnection management code (in no particular order):</p> <ul><li>A <code>T_LISTEN</code> event is cleared by <code>OTListen</code>.</li><li>A <code>T_DISCONNECT</code> event is cleared by <code>OTRcvDisconnect</code>.</li><li>A <i>call</i> is cleared by <code>OTAccept</code>, <code>OTSndDisconnect</code>, <code>OTRcvDisconnect</code>.</li><li>An <code>OTListen</code> can get a <code>kOTLookErr</code> because a <code>T_DISCONNECT</code> is on the top of thestream.</li><li>An <code>OTAccept</code> can get a <code>kOTLookErr</code> because a <code>T_DISCONNECT</code> or <code>T_LISTEN</code> is on thetop of the stream.</li><li>An <code>OTRcvDisconnect</code> can get a <code>kOTLookErr</code> because a <code>T_DISCONNECT</code> is on the topof the stream.</li><li>An <code>OTSndDisconnect</code> cannot get a <code>kOTLookErr</code>.</li></ul><B>An Example</B><p>Properly handling these connect requests requires you to be able tosimultaneously process the number of <i>calls</i> that you specified in thequeue length.</p><p>For example: </p><ol><li>Assume you specified a qlen of 5 in the OTBind.</li><li>The client end sends you a connection request.</li><li>Your notifier receives a <code>T_LISTEN</code> event.</li><li>You invoke <code>OTListen</code> to get the <i>call.</i></li><li>You do an <code>OTAccept</code> on the <i>call.</i> </li><li><code>OTAccept</code> returns an <code>kOTLookErr</code>, because another <code>T_LISTEN</code> event is pending.</li></ol><P>This can continue until you have filled the queue with 5 inbound connectionrequests, at which point Open Transport will automatically refuse any furtherconnection requests on that endpoint.</p><B>The Solution</B><p>You can apply the following strategy to handle processing inbound connectionrequests.</p><p>We're going to set up a example scenario of accepting connections from ourlistening endpoint. Let's make the following assumptions:</p> <ul><li>You are using endpoints in asynchronous/blocking mode.</li><li>You have a queue length greater than 1.</li><li>You are handing connections off from a listening endpoint to acceptorendpoints.</li><li>You do most of the work inside your notifier routine.</li></ul><P>Here's the scenario: </p><p>The first thing you want to do is create a list (LIST) or array of call (CALL)instances large enough to handle your queue.</p><ol><li>When your notifier gets a <code>T_LISTEN</code> event, call <code>OTListen</code> in a loop until you geta <code>kOTNoDataErr</code> or a <code>kOTLookErr</code>. For each <code>OTListen</code> which returns <code>kOTNoError</code>,queue the CALL to the LIST for later processing. If the result is <code>kOTNoDataErr</code>,you have already gotten all of the CALLs, so go to step #3. If the result is<code>kOTLookErr</code>, it is because of a <code>T_DISCONNECT</code> event. Go to step #2.</li><li>Do an <code>OTRcvDisconnect</code> and get the associated CALL's sequence number. Find thatCALL in the LIST and delete it. Return to step #1.</li><li>If the LIST is not empty, take the first CALL and determine if you want toaccept it. If you want to accept it, go to step #4. To reject it, go to step#5.</li><li>Call <code>OTAccept</code> on the CALL. If the result is <code>kOTNoError</code>, delete the CALL fromthe LIST and return out of the notifier. If the result is kOTLookErr, do  a<code>OTLook</code>. If the look result is T_LISTEN, go to step #1. If the look result is<code>T_DISCONNECT</code>, go to step #2.</li><li>Call <code>OTSndDisconnect</code> on the CALL. If the result is <code>kOTNoError</code>, delete the CALLfrom the LIST and return out of the notifier. If the result is <code>kOTLookErr</code>, goto step #2, <code>T_DISCONNECT</code> is the only reason <code>OTSndDisconnect</code> can return a lookerror.</li><li>When your notifier gets a <code>T_PASSCON</code>, check to see if the <code>T_ACCEPTCOMPLETE</code> hasalready happened. If not, return out of the notifier. If so, go back to step#3.</li><li>When your notifier gets a <code>T_ACCEPTCOMPLETE</code>, check the result. If the result isanything other than <code>kOTNoError</code>, you won't be getting a <code>T_PASSCON</code> event. Do theappropriate error handling, then return to step #3. If the result is<code>kOTNoError</code>, check to see if the <code>T_PASSCON</code> has already happened. If not, returnout of the notifier. If so, go back to step #3.</li><li>When your notifier gets a <code>T_DISCONNECTCOMPLETE</code>, go back to step #3.</li></ol><P>Alternatively, you could make step #3 a loop and handle all of the CALLs in theLIST simultaneously, but that makes handling the <code>T_ACCEPTCOMPLETE</code> / <code>T_PASSCON</code>events and LIST processing more complicated. In general, the added complexitymay not be worth it.</p><P>If you don't handle everything inside your notifier, there's one gotcha: if youset a flag in your notifier and process the event back in your main thread, youmust deal with the following type of synchronization issue: </p><P>There is a <code>T_LISTEN</code> on top of the queue hiding a <code>T_DISCONNECT</code>. Your notifiergets a <code>T_LISTEN</code> and you set a flag to handle it back in the main thread. Themain thread does an OTListen, which clears the <code>T_LISTEN</code> and brings the<code>T_DISCONNECT</code> up to the top. Before the <code>OTListen</code> completes, your notifier willbe interrupted with the <code>T_DISCONNECT</code> notification.</p><p>Once you understand how things work, handling <code>kOTLookErr</code> is not as perplexingas it might seem.</p><H3>Negotiate qlen on Bind</H3><p>As mentioned at the beginning of this section, you specify the length of alistening endpoint's connection queue when you bind a connection-orientedservice, such as TCP or ADSP. During the bind process, however, it is possiblefor the value of queue length to be negotiated by the endpoint. This length maybe changed if the endpoint cannot support the requested number of outstandingconnection indications. Therefore, it is important for your application not toassume that the value of qlen returned by the <code>OTBind</code> is the same as requested.You should always check it.</p><P><A HREF="#top">Back to top</A></P><a name = "RTFToC5"></a><H2>Increasing Throughput</H2><p>This section discusses methods for increasing network data throughput to yourserver to enhance performance.</p><H3>No-Copy Receive</H3><P>When properly used, no-copy receives may provide a significant performanceenhancement by letting you directly access the network interface's actual DMAbuffers. This process lets you determine where and how to copy data; typically,this results in decreasing memory copies by a factor of 2.</p><p>To request that Open Transport initiate a no-copy receive, you must pass theconstant <code>kOTNetbufDataIsOTBufferStar</code> in the length parameter of the <code>OTRcv</code>. Thiswill return you a pointer to the OTBuffer structure, as illustrated here: </p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>OTBuffer* myBuffer;OTResult result = OTRcv(myEndpoint, &amp;myBuffer,kOTNetbufDataIsOTBufferStar);</pre>	</TD></TR></TABLE></CENTER><p>The <code>OTBuffer</code> data structure is based on the STREAMS <code>mblk_t</code> data structure, asillustrated below. By tracing the chain of <code>fNext</code> pointers, all of the dataassociated with the message can be accessed.</p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>struct OTBuffer{    void*        fLink;        // b_next &amp; b_prev    void*        fLink2;    OTBuffer*    fNext;        // b_cont    UInt8*        fData;        // b_rptr    size_t        fLen;        // b_wptr    void*        fSave;        // b_datap    UInt8        fBand;        // b_band    UInt8        fType;        // b_pad1    UInt8        fPad1;    UInt8        fFlags;        // b_flag};</pre>	</TD></TR></TABLE></CENTER><P>A few utilities are available to the Open Transport programmer tosimplify access to the <code>OTBuffer</code> structure. You can use <code>OTReadBuffer</code> to readdata from the buffer, to <code>OTBufferDataSize</code> calculate its total length and<code>OTReleaseBuffer</code> to dispose of the <code>OTBuffer</code> when you are done.</p><P>When processing a no-copy receive, it is very important that you minimize thetime that you hold onto the buffer and be sure to call <code>OTReleaseBuffer</code> toreturn it to Open Transport. Otherwise, you run the risk of starving thenetwork driver for DMA buffers and adversely affecting the performance of theoperating system.</p>    Warning:         Under no circumstances should you write to the OTBufferdata structure. Doing so will run the result in either an an access fault orsystem crash.<p>The <i>Open Transport Client Developer Note </i>further documents the no-copyreceive method of processing network data.</p><H3>A Code Snippet Illustrating a No-Copy Receive </H3><p>This snippet demonstrates how you might process a no-copy receive in yournotifier: </p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>#include &lt;openTransport.h&gt;#include &lt;OpenTptClient.h&gt;//  QUEUE_NET_EVENT(T_DATA) defers a particular event to later//  MyProcessBuffer(buffer,actCount) consumes network datavoid HandleDataAvail(EndpointRef ep) {        OTFlags             flags;        OTResult            status;        OTBuffer*        buffP;        OTBufferInfo        buffInfo;        size_t            actCount;        char*            buffer;// Do while data left in OT    while((status = : : OTRcv(ep, &amp;buffP,                         kOTNetbufDataIsOTBufferStar, &amp;flags)) &gt; 0)     {    // Get count of bytes in buffer        OTInitBufferInfo(&amp;buffInfo, buffP);        actCount = status;    // Reserve buffer space    // You should handle OTAllocMem failures. Maybe use a deferred task.        ThrowIfNil(buffer = OTAllocMem(actCount));    // Read data into buffer        : : OTReadBuffer(&amp;buffInfo, buffer, &amp;actCount);    // Call code to consume network data        MyProcessBuffer(buffer,actCount);    // Return OTBuffer to system        : : OTReleaseBuffer(buffP);    }// Did we read all the data ?         if(status == kOTNoDataErr) return;// Was the endpoint not ready yet?         else if(status == kOTStateChangeErr) QUEUE_NET_EVENT(T_DATA);// Check for Rcv Error        else ThrowIfErr( status );};</pre>	</TD></TR></TABLE></CENTER><H3>Using AckSend</H3><p>By enabling the <code>AckSend</code> option on endpoint, you can eliminate the need for OpenTransport to perform a memory copy of contiguous data to be transmitted by<code>OTSnd</code>. Instead, a pointer to the data will be passed downstream. Once thememory is no longer being used, the notifier receives a <code>T_MEMORYRELEASED</code> event.</p>    <BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Note:</B><BR>         You don't have to wait for the <code>T_MEMORYRELEASED</code> event beforecalling <code>OTSnd</code> again, however you can't reuse any memory that you passed <code>OTSnd</code>until Open Transport has released it through the <code>T_MEMORYRELEASED</code> event.</P></TD></TR></TABLE></CENTER><BR><p>The following snippet provides an example of usage: </p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>OTAckSends(ep)                 // enable AckSend option......buf = OTAllocMem( nbytes);        // Allocate nbytes of memory from OTOTSnd(ep, buf, nbytes, 0);        // send a packet......NotifyProc( .... void* theParam)    // Notifier Proccase T_MEMORYRELEASED:        // process event        OTFreeMem( theParam);    // free up memory        break;</pre>	</TD></TR></TABLE></CENTER>    <BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Note:</B><BR>         Because of the complexity of handling endpoint flow-control, Open Transport performance will suffer when the <code>AckSend</code> option is used to handlenon-contiguous data, i.e., <code>OTSnd</code> that have been passed a <code>OTData</code> structure.Therefore, use <code>AckSend</code> only when sending contiguous data.</P></TD></TR></TABLE></CENTER><BR><H3>Handling Dead Clients</H3><p>A properly-designed server should be prepared to handle what happens when aremote client unexpectedly disappears. The problem of a disappearing (orcrashed) client is further aggravated when the link has been flow-controlled.This is illustrated in the following scenario: </p><ol><li>You are transmitting a large amount of data to a client.</li><li>Your transport provider enters a flow-control state.</li><li>The client crashes or becomes unreachable.</li><li>After a timeout your server decides to force a disconnect from that client andissues a disconnect request.</li><li>But under XTI the stream <code>T_DISCON_REQ</code> is a <code>M_PROTO</code> message and is thus also subject to flow control; this causes your link to hang.</li></ol><p>Under XTI it is the application's responsibility to flush the stream beforeissuing a disconnect. The best way to force a flush is by sending the IFLUSHcommand to the stream head with an OTIoctl. As illustrated here: </p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>#include &lt;stropts.h&gt;error = OTIoctl(ep, IFLUSH,  (void*) FLUSHRW);if (error)  OTUnBind(ep)</pre>	</TD></TR></TABLE></CENTER><H3>Sending Large Blocks of Data</H3><P>Another way to improve the performance of a high volume network server is byminimizing the overhead incurred by <code>OTSnd</code>. You can do this by sending as largea block as the endpoint's transport service data unit (TSDU) will allow, thusreducing the number of times <code>OTSnd</code> is called.</p><P>You can determine the endpoints TSDU size by inspecting the <code>TEndpointInfo</code>returned by <code>OTOpenEndpoint</code> or <code>OTGetEndpointInfo</code>.</p><P>For endpoints that support infinite data unit size (<code>T_INFINITE</code>) such as TCP/IP,empirical evidence suggests that a size around 8K bytes might be optimal.</p><P>There are a number of tradeoffs involved in selecting the proper size block topass to <code>OTSnd</code>, but the overall guideline is to do whatever you can to keep theoutbound pipe full.</p><H3>Flow Control</H3><P>To take optimal advantage of Open&nbsp;Transport's throughput, your servershould attempt to keep the outbound data stream full. In order to do this, yourapplication must properly handle flow-control restrictions. Flow-controlrestrictions are imposed by Open Transport when only a part of the data passedto an endpoint can be accepted by the transport provider. This may be due tomany things, including local memory restrictions or even network throughputlimitations. In order to prevent data loss, Open Transport will impose aflow-control state on that endpoint.</p><P>How Open Transport handles flow control for a given endpoint depends on thatendpoint's blocking mode. When an endpoint is in blocking mode, a send requestsuch as <code>OTSnd</code> will wait for flow control to lift, then complete the send.</p><P>Conversely, when an endpoint is in non-blocking mode, <code>OTSnd</code> will returnimmediately with a value that is less than the value of the number of bytespassed to it, or if no bytes at all were sent, it will return <code>kOTFlowErr</code>.</p><P>Once in a flow-control state, the endpoint will remain there until the remoteside has accepted the pending data. Once the flow-control restrictions arelifted your notifier will be issued a <code>T_GODATA</code> or <code>T_GOEXDATA</code> event.</p><P>Under a low memory condition it is possible for <code>OTSnd</code> to return a <code>kENOMEMErr</code>. Inthis case, you should back off and attempt to send later, possibly by means ofa timer. Unlike the <code>kOTFlowErr</code> case, your application is not flow controlledand thus your notifier will not get a <code>T_GODATA</code> event.</p>    <BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Note:</B><BR>         If your application is calls <code>OTSnd</code> outside of your notifier --for instance, at System Task time -- it should be prepared to handle problemssimilar to the <code>OTRcv/T_DATA</code> case outlined in the section AvoidingSynchronization Problems.</P></TD></TR></TABLE></CENTER><BR><P><A HREF="#top">Back to top</A></P><a name = "RTFToC6"></a><H2>Other Tips to Improve Performance</H2><p>There are a few other points that you should be aware of to get the most out ofOpen Transport in your network server design.</p><H3>Using the Native OT API Rather Than MacTCP</H3><p>There is no excuse for your server application not to use the native OT API.Here are some of the reasons why: </p><ul><li>MacTCP is based on the 68K Device Manager model, which on a PPC requiresextensive mode switches.</li><li>MacTCP has an inherent limitation of 64 concurrent endpoints.</li><li>MacTCP cannot be extended to support multihomming.</li><li>Open Transport provides a modern implementation of the TCP stack.</li></ul><p>But for servers, the primary reason to use the OT API is performance. Forexample: Experiments over Ethernet on 68K systems have yielded a throughput ofsomewhere between 300-400k bits/sec using MacTCP vs 600-800k bits/sec usingOpen Transport. On the PPC, the numbers are more impressive, exceeding theEthernet speed of 1.5M bits/sec. Preliminary tests indicate speeds approaching90% link utilization ATM.</p><H3>Tuning Server Memory Allocation</H3><P>Another option for improving server performance is to modify Open Transport'smemory allocation limits. If you intend for your server application to run on adedicated Macintosh, this is an effective way to ensure that enough bufferspace is available to maintain a high transaction rate.</p><P>Starting with version 1.1.1, you will be able to use <code>OTSetMemoryLimits</code> todirect Open Transport to grow its internal client memory pool. You should usethis API instead of the <code>OTSetServerMode</code>. <code>OTSetMemoryLimits</code> takes two arguments,a size to grow now and a maximum limit to expand the memory pool.</p><P>Remember to call <code>OTSetMemoryLimits(0,0)</code> before quitting your server to informOpen Transport that specialized memory requirements are no longer required.</p><P>The prototype for <code>OTSetMemoryLimits</code> is not currently available in the "<i>OpenTransport.h</i>" include file. You should use the following: </p><CENTER><TABLE BORDER=0 CELLPADDING=5 WIDTH=550><TR>	<td bgcolor="#E6E6E6" align=left><pre>  extern  OSStatus OTSetMemoryLimits(size_t growSize, size_t maxSize);</pre>	</TD></TR></TABLE></CENTER><BR><CENTER><TABLE BORDER=0 WIDTH=550><TR><td bgcolor="#E6E6E6" align=left><P><B>Warning:</B><BR>Although currently available, you should be aware  <code>OTSetServerMode</code> and<code>OTSetMemoryLimits</code> may not be supported the future versions ofOpen&nbsp;Transport. To be sure, check with Apple Developer TechnicalSupport.</P></TD></TR></TABLE></CENTER><BR><H3>Server Shutdown</H3><p>Server developers typically neglect to handle issues related to quitting theirapplications. To shut down an Open Transport network server properly, you needto be sure that your application performs the following items: </p><ul><li>Ensure that all network and I/O has either completed or aborted.</li><li>Flush any flow-controlled data streams with the <code>IFLUSH</code> <code>ioctl</code>.</li><li>Unbind and Close all endpoints.</li><li>Cancel any Deferred Tasks with <code>OTDestroyDeferredTask</code>.</li><li>Release any <code>OTBuffer</code> structures with <code>OTReleaseBuffer</code>.</li><li>Dispose of any unused <code>OTConfiguration</code> structures withOTDestroyConfiguration.</li><li>Call <code>OTSetMemoryLimits(0,0)</code> to reset memory allocations.</li></ul><H3>Protocol Specific Issues</H3><P>Depending on the provider and the version of Open Transport that you are usingthere are specific optimization and techniques that you should be aware of thatbe applied to enhance server performance. The best source for this informationis the <i>Open Transport Client Developer Note </i>and the <i>Open TransportRelease Notes. </i>You should also check the <a href="http://developer.apple.com/macos/opentransport/">Apple Open Transport Website</a> for the latest information.</p><p><B>AppleTalk and ADSP</B></p><p>All the topics addressed in this Technote also apply to ADSP.</p><p><B>TCP/IP - Avoiding 2 minute delay on bind</B></p><p>In order to prevent stale data from corrupting a new connection, TCP imposes a2-minute timeout on a binding after a connection has closed, before allowingthe same port to bound to again. This can be worked around by setting the<code>IP_REUSEADDR</code> option with an OTOptionManagement call.</p><p>This technique is further documented in the Macintosh Technical Q&amp;A, <a href="../../qa/nw/nw28.html">NW 28 - TCP Application Acquires Different Port Address After Relaunch</a>.</p><P><A HREF="#top">Back to top</A></P><a name = "Summary"></a><H2>Summary</H2><P>Because performance issues are a source of concern for developers who writenetwork server applications, the techniques outlined in this Note offer you aset of suggestions you ought to consider in order to improve server throughput.Using notifiers properly is essential to packet processing latency. Inaddition, using the File Manager efficiently in conjunction with Open Transportwill directly increase your throughput.</p><p>The more you know about how Open Transport interacts with the Mac OS, thebetter you'll be able to design applications that take full advantage of itsperformance. </p><P><A HREF="#top">Back to top</A></P><A NAME="References"></a><H2>References</h2><p>Apple Open Transport Website<br><A HREF = "http://developer.apple.com/macos/opentransport/">&lt;http://developer.apple.com/macos/opentransport/&gt;</a></p><p>Open Transport Client Developer Note</p><p>"Open Transport.h " header file</p><p>Inside Macintosh: Open Transport</p><p>Inside Macintosh: Files</p><p>X/Open CAE Specification, X/Open Transport Interface (XTI), Version2./Open Company Ltd ISBN# 0-13-353459-6,<A HREF = "http://www.opengroup.org/index.htm/">&lt;http://www.opengroup.org/index.htm/&gt;</a></p><p><I><a href="../fl/fl_16.html">Technote FL 16 - File Manager Performance and Caching</a></I></p><P><A HREF="#top">Back to top</A></P>         <P><A NAME=Downloads></A></P>                  <H2>Downloadables</H2>                  <TABLE BORDER=0 CELLPADDING=3 WIDTH="500">            <TR>               <td width=50 align=left>                  <P ALIGN=center><img src="images/acrobatsmall.gif" width=22 height=23 align=middle alt="Acrobat"></P>               </TD>               <td align="left">                  <P>Acrobat version of this Note (84K).</P>               </TD>               <td width=60 align=left>                  <P><A HREF="pdf/tn1059.pdf">Download</A></P>               </TD>            </TR></TABLE><P><A HREF="#top">Back to top</A></P></TD></TR></table></center><!-- begin_footer_information -->	<table width="680" border="0" cellpadding="0" cellspacing="0">
		<tr>
			<td><div style="width: 100%; height: 1px; background-color: #919699; margin-top: 5px; margin-bottom: 15px"></div></td>
		</tr>
		<tr>
			<td align="center"><br/>
				<table border="0" cellpadding="0" cellspacing="0" class="graybox">
					<tr>
						<th>Did this document help you?</th>
					</tr>
					<tr>
						<td>
						    <div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=1&url=/technotes/tn/tn1059.html%3Fid%3DDTS10002900-1.0&media=dvd" target=_new>Yes</a>:  Tell us what works for you.</div>
							<div style="margin-bottom: 8px"><a href="http://developer.apple.com/feedback/?v=2&url=/technotes/tn/tn1059.html%3Fid%3DDTS10002900-1.0&media=dvd" target=_new>It&#8217;s good, but:</a> Report typos, inaccuracies, and so forth.</div>
							<div><a href="http://developer.apple.com/feedback/?v=3&url=/technotes/tn/tn1059.html%3Fid%3DDTS10002900-1.0&media=dvd" target=_new>It wasn&#8217;t helpful</a>: Tell us what would have helped.</div>
						</td>
					</tr>
				</table>
			</td>
		</tr>
	</table>
<!--#include virtual="/includes/footer"--><!-- end_footer_information --></BODY></HTML>